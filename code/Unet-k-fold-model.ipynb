{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "meaningful-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handy-liberal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Input, MaxPooling2D, UpSampling2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "from tensorflow.keras.models import Model\n",
    "from keras import backend as K\n",
    "from dataGenerator import gen_train_data, test_data\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_weight = 'model_weight.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interpreted-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy and loss\n",
    "def iu_acc(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    smooth = 1e-12\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    jac = (intersection) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "def dice_acc(y_true, y_pred):\n",
    "    smooth = 1e-12\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    jac = (2*intersection + smooth) / (sum_ + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "# loss function\n",
    "def my_loss(y_true,y_pred):\n",
    "    bc = K.binary_crossentropy(y_pred, y_true)\n",
    "    false_bc = (1.0 - y_true) * bc\n",
    "    true_bc = y_true * bc\n",
    "    mloss = false_bc + 10.0 * true_bc\n",
    "    return mloss\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# dice_coef may have better performance\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def ConvActive(np_ker, size, inputs, \n",
    "                        initial = initializers.glorot_normal(seed=None)):\n",
    "    \n",
    "    return Conv2D(np_ker, size, activation='relu',padding = 'same', kernel_initializer = initial)(inputs)\n",
    "\n",
    "def ConvBatchnormActive(np_ker, size, inputs, \n",
    "                        initial = initializers.glorot_normal(seed=None)):\n",
    "    \n",
    "    return Activation('relu')(BatchNormalization()(Conv2D(np_ker, size,padding = 'same', kernel_initializer = initial)(inputs)))\n",
    "\n",
    "def UpConvActiveContact(np_ker, size, inputs, contact,\n",
    "                  initial = initializers.glorot_normal(seed=None)):\n",
    "    up = UpSampling2D(size = (2,2))(inputs)\n",
    "    upconv = Conv2D(np_ker, size, activation = 'relu', padding = 'same', kernel_initializer = initial)(up) \n",
    "    return Concatenate(axis=3)([upconv, contact])\n",
    "\n",
    "def get_unet(pretrained_weights = None):\n",
    "    \n",
    "    inputs = Input((512, 512, 3))\n",
    "\n",
    "    conv1 = ConvBatchnormActive(16, 3, inputs)\n",
    "    conv1 = ConvBatchnormActive(16, 3, conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "    \n",
    "    conv2 = ConvBatchnormActive(32, 3, pool1)\n",
    "    conv2 = ConvBatchnormActive(32, 3, conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = ConvBatchnormActive(64, 3, pool2)\n",
    "    conv3 = ConvBatchnormActive(64, 3, conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = ConvBatchnormActive(128, 3, pool3)\n",
    "    conv4 = ConvBatchnormActive(128, 3, conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    conv5 = ConvBatchnormActive(256, 3, pool4)\n",
    "    conv5 = ConvBatchnormActive(256, 3, conv5)\n",
    "    \n",
    "    up6 = UpConvActiveContact(128, 2, conv5, conv4)\n",
    "    up6 = Dropout(0.5)(up6)\n",
    "    conv6 = ConvBatchnormActive(128, 3, up6)\n",
    "    conv6 = ConvBatchnormActive(128, 3, conv6)\n",
    "    \n",
    "    up7 = UpConvActiveContact(64, 2, conv6, conv3)\n",
    "    up7 = Dropout(0.5)(up7)\n",
    "    conv7 = ConvBatchnormActive(64, 3, up7)\n",
    "    conv7 = ConvBatchnormActive(64, 3, conv7)\n",
    "    \n",
    "    up8 = UpConvActiveContact(32, 2, conv7, conv2)\n",
    "    up8 = Dropout(0.5)(up8)\n",
    "    conv8 = ConvBatchnormActive(32, 3, up8)\n",
    "    conv8 = ConvBatchnormActive(32, 3, conv8)\n",
    "    \n",
    "    up9 = UpConvActiveContact(16, 2, conv8, conv1)\n",
    "    up9 = Dropout(0.5)(up9)\n",
    "    conv9 = ConvBatchnormActive(16, 3, up9)\n",
    "    conv9 = ConvBatchnormActive(16, 3, conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "    \n",
    "    model.compile(optimizer = 'Adam', loss = dice_coef_loss, metrics = [iu_acc, dice_acc, 'accuracy'])\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bearing-tradition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 512, 512, 16) 64          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512, 512, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 2320        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 16) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 256, 16) 0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 4640        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256, 256, 32) 128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 256, 256, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 32) 9248        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 32) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 18496       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 64) 256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128, 128, 64) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 64)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 128)  73856       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64, 64, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 128)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 256)  295168      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  590080      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 64, 64, 256)  0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 256)  0           conv2d_10[0][0]                  \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 64, 256)  0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  295040      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 64, 64, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  147584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 128 0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 128 0           conv2d_13[0][0]                  \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128, 128, 128 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 73792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 128, 128, 64) 256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 128, 128, 64) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 36928       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64) 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 64) 0           conv2d_16[0][0]                  \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 256, 256, 64) 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 18464       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256, 256, 32) 128         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 256, 256, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 32) 9248        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 32) 128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 32) 0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 512, 512, 16) 2064        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512, 512, 32) 0           conv2d_19[0][0]                  \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 512, 512, 32) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 16) 4624        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 512, 512, 16) 64          conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 512, 512, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 16) 2320        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 16) 64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 1)  17          activation_17[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,946,993\n",
      "Trainable params: 1,944,049\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "substantial-taste",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2021-07-29 08:23:42.315459\n",
      "Found 90 images belonging to 1 classes.\n",
      "Found 90 images belonging to 1 classes.\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002E4E1850438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002E4E1850438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function dice_coef_loss at 0x000002E4DD95D708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function dice_coef_loss at 0x000002E4DD95D708> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function iu_acc at 0x000002E4B7EFEA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function iu_acc at 0x000002E4B7EFEA68> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function dice_acc at 0x000002E42F039D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function dice_acc at 0x000002E42F039D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10000/10000 [==============================] - ETA: 0s - loss: -0.8642 - iu_acc: 0.8241 - dice_acc: 0.8882 - accuracy: 0.9924WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002E4E9B22048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002E4E9B22048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "10000/10000 [==============================] - 1070s 107ms/step - loss: -0.8642 - iu_acc: 0.8241 - dice_acc: 0.8882 - accuracy: 0.9924 - val_loss: -0.9774 - val_iu_acc: 0.8953 - val_dice_acc: 0.9421 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00001: loss improved from inf to -0.92905, saving model to D:/Anil/saved_model/gray_mold/k-fold-cv/Unet_kf1_50epoch_10000_it.hdf5\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1395s 140ms/step - loss: -0.9502 - iu_acc: 0.8845 - dice_acc: 0.9353 - accuracy: 0.9973 - val_loss: -0.9795 - val_iu_acc: 0.9125 - val_dice_acc: 0.9528 - val_accuracy: 0.9978\n",
      "\n",
      "Epoch 00002: loss improved from -0.92905 to -0.95296, saving model to D:/Anil/saved_model/gray_mold/k-fold-cv/Unet_kf1_50epoch_10000_it.hdf5\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 1753s 175ms/step - loss: -0.9572 - iu_acc: 0.8958 - dice_acc: 0.9427 - accuracy: 0.9977 - val_loss: -0.9803 - val_iu_acc: 0.8954 - val_dice_acc: 0.9426 - val_accuracy: 0.9979\n",
      "\n",
      "Epoch 00003: loss improved from -0.95296 to -0.95773, saving model to D:/Anil/saved_model/gray_mold/k-fold-cv/Unet_kf1_50epoch_10000_it.hdf5\n",
      "Epoch 4/50\n",
      " 2431/10000 [======>.......................] - ETA: 26:08 - loss: -0.9570 - iu_acc: 0.8959 - dice_acc: 0.9429 - accuracy: 0.9978"
     ]
    }
   ],
   "source": [
    "#%% training from scratch\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('D:/Anil/saved_model/gray_mold/k-fold-cv/Unet_kf1_50epoch_10000_it.hdf5', monitor = 'loss', verbose = 1, save_best_only =True)\n",
    "callback_checkpoint = [model_checkpoint]\n",
    "\n",
    "path_train = 'D:/Anil/Dataset/gray_mold/k-fold/kf1/train/'\n",
    "path_test = 'D:/Anil/Dataset/gray_mold/k-fold/kf1/test/'\n",
    "\n",
    "# model = get_unet()\n",
    "train_data = gen_train_data(path_train)\n",
    "test_data = test_data(path_test)\n",
    "start_time = datetime.now()\n",
    "print(\"Start time: {}\".format(start_time))\n",
    "history = model.fit(train_data, steps_per_epoch=10000, epochs=50, verbose=1, \n",
    "                    shuffle=True, validation_data=test_data, callbacks = callback_checkpoint)\n",
    "\n",
    "end_time = datetime.now()\n",
    "total_time = end_time - start_time\n",
    "print(\"Total time taken: {}\".format(total_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-student",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_dict = pd.DataFrame(history.history) \n",
    "hist_csv_file = \"D:/Anil/saved_model/gray_mold/k-fold-cv/kf1/kf1_model_history_50epochs_10000_it.csv\"\n",
    "with open(hist_csv_file, mode='w', newline = '') as f:\n",
    "    history_dict.to_csv(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "streaming-trauma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-request",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "buried-canvas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
