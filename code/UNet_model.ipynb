{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.compat.v1.Session(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers import Input, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import BatchNormalization, Concatenate, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from dataGenerator import gen_train_data, test_data\n",
    "from keras.callbacks import ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_weight = 'model_weight.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy and loss\n",
    "def iu_acc(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    smooth = 1e-12\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    jac = (intersection) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "def dice_acc(y_true, y_pred):\n",
    "    smooth = 1e-12\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    sum_ = K.sum(y_true + y_pred_pos, axis=[1, 2, 3], keepdims=False)\n",
    "    jac = (2*intersection + smooth) / (sum_ + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "# loss function\n",
    "def my_loss(y_true,y_pred):\n",
    "    bc = K.binary_crossentropy(y_pred, y_true)\n",
    "    false_bc = (1.0 - y_true) * bc\n",
    "    true_bc = y_true * bc\n",
    "    mloss = false_bc + 10.0 * true_bc\n",
    "    return mloss\n",
    "\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# dice_coef may have better performance\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def ConvActive(np_ker, size, inputs, \n",
    "                        initial = initializers.glorot_normal(seed=None)):\n",
    "    \n",
    "    return Conv2D(np_ker, size, activation='relu',padding = 'same', kernel_initializer = initial)(inputs)\n",
    "\n",
    "def ConvBatchnormActive(np_ker, size, inputs, \n",
    "                        initial = initializers.glorot_normal(seed=None)):\n",
    "    \n",
    "    return Activation('relu')(BatchNormalization()(Conv2D(np_ker, size,padding = 'same', kernel_initializer = initial)(inputs)))\n",
    "\n",
    "def UpConvActiveContact(np_ker, size, inputs, contact,\n",
    "                  initial = initializers.glorot_normal(seed=None)):\n",
    "    up = UpSampling2D(size = (2,2))(inputs)\n",
    "    upconv = Conv2D(np_ker, size, activation = 'relu', padding = 'same', kernel_initializer = initial)(up) \n",
    "    return Concatenate(axis=3)([upconv, contact])\n",
    "\n",
    "def get_unet(pretrained_weights = None):\n",
    "    \n",
    "    inputs = Input((512, 512, 3))\n",
    "\n",
    "    conv1 = ConvBatchnormActive(16, 3, inputs)\n",
    "    conv1 = ConvBatchnormActive(16, 3, conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "    \n",
    "    conv2 = ConvBatchnormActive(32, 3, pool1)\n",
    "    conv2 = ConvBatchnormActive(32, 3, conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    pool2 = Dropout(0.5)(pool2)\n",
    "    \n",
    "    conv3 = ConvBatchnormActive(64, 3, pool2)\n",
    "    conv3 = ConvBatchnormActive(64, 3, conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(0.5)(pool3)\n",
    "    \n",
    "    conv4 = ConvBatchnormActive(128, 3, pool3)\n",
    "    conv4 = ConvBatchnormActive(128, 3, conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(0.5)(pool4)\n",
    "    \n",
    "    conv5 = ConvBatchnormActive(256, 3, pool4)\n",
    "    conv5 = ConvBatchnormActive(256, 3, conv5)\n",
    "    \n",
    "    up6 = UpConvActiveContact(128, 2, conv5, conv4)\n",
    "    up6 = Dropout(0.5)(up6)\n",
    "    conv6 = ConvBatchnormActive(128, 3, up6)\n",
    "    conv6 = ConvBatchnormActive(128, 3, conv6)\n",
    "    \n",
    "    up7 = UpConvActiveContact(64, 2, conv6, conv3)\n",
    "    up7 = Dropout(0.5)(up7)\n",
    "    conv7 = ConvBatchnormActive(64, 3, up7)\n",
    "    conv7 = ConvBatchnormActive(64, 3, conv7)\n",
    "    \n",
    "    up8 = UpConvActiveContact(32, 2, conv7, conv2)\n",
    "    up8 = Dropout(0.5)(up8)\n",
    "    conv8 = ConvBatchnormActive(32, 3, up8)\n",
    "    conv8 = ConvBatchnormActive(32, 3, conv8)\n",
    "    \n",
    "    up9 = UpConvActiveContact(16, 2, conv8, conv1)\n",
    "    up9 = Dropout(0.5)(up9)\n",
    "    conv9 = ConvBatchnormActive(16, 3, up9)\n",
    "    conv9 = ConvBatchnormActive(16, 3, conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs = inputs, outputs = conv10)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = dice_coef_loss, metrics = [iu_acc, dice_acc, 'accuracy'])\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 16) 64          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 16) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 16) 2320        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 16) 64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 512, 16) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 16) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 256, 16) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 32) 4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 32) 128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 32) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 32) 9248        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 32) 128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 256, 32) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 32) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 32) 0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 64) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 64)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 64)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 128)  73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 128)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 128)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 128)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 256)  295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 256)  590080      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 256)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 256)  0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  131200      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 256)  0           conv2d_11[0][0]                  \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 128)  295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 128)  147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 128)  512         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 128 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 64) 32832       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 128 0           conv2d_14[0][0]                  \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128, 128, 128 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 64) 73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128, 128, 64) 256         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 128, 128, 64) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 64) 36928       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 64) 256         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 64) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 64) 0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 32) 8224        up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 64) 0           conv2d_17[0][0]                  \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 256, 256, 64) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 32) 18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 256, 256, 32) 128         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256, 256, 32) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 32) 9248        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 32) 128         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256, 256, 32) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 32) 0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 16) 2064        up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 32) 0           conv2d_20[0][0]                  \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 512, 512, 32) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 16) 4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 512, 512, 16) 64          conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 512, 512, 16) 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 16) 2320        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 512, 512, 16) 64          conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 512, 512, 16) 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 512, 512, 1)  17          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,946,993\n",
      "Trainable params: 1,944,049\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_unet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Found 90 images belonging to 1 classes.\n",
      "Found 90 images belonging to 1 classes.\n",
      "10000/10000 [==============================] - 1241s 124ms/step - loss: -0.8069 - iu_acc: 0.8314 - dice_acc: 0.8952 - accuracy: 0.9939 - val_loss: -0.9611 - val_iu_acc: 0.8694 - val_dice_acc: 0.9206 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00001: loss improved from inf to -0.80692, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 2/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9539 - iu_acc: 0.8917 - dice_acc: 0.9408 - accuracy: 0.9976 - val_loss: -0.9533 - val_iu_acc: 0.8785 - val_dice_acc: 0.9334 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00002: loss improved from -0.80692 to -0.95386, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 3/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9575 - iu_acc: 0.8979 - dice_acc: 0.9442 - accuracy: 0.9977 - val_loss: -0.9404 - val_iu_acc: 0.8764 - val_dice_acc: 0.9312 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00003: loss improved from -0.95386 to -0.95751, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 4/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9599 - iu_acc: 0.9023 - dice_acc: 0.9475 - accuracy: 0.9979 - val_loss: -0.9477 - val_iu_acc: 0.8753 - val_dice_acc: 0.9314 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00004: loss improved from -0.95751 to -0.95993, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 5/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9619 - iu_acc: 0.9071 - dice_acc: 0.9499 - accuracy: 0.9979 - val_loss: -0.9551 - val_iu_acc: 0.8812 - val_dice_acc: 0.9345 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00005: loss improved from -0.95993 to -0.96190, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 6/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9631 - iu_acc: 0.9090 - dice_acc: 0.9515 - accuracy: 0.9980 - val_loss: -0.9519 - val_iu_acc: 0.8379 - val_dice_acc: 0.8979 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00006: loss improved from -0.96190 to -0.96313, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 7/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9643 - iu_acc: 0.9106 - dice_acc: 0.9524 - accuracy: 0.9981 - val_loss: -0.9633 - val_iu_acc: 0.9151 - val_dice_acc: 0.9549 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00007: loss improved from -0.96313 to -0.96433, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 8/50\n",
      "10000/10000 [==============================] - 1237s 124ms/step - loss: -0.9655 - iu_acc: 0.9138 - dice_acc: 0.9537 - accuracy: 0.9981 - val_loss: -0.9579 - val_iu_acc: 0.8997 - val_dice_acc: 0.9461 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00008: loss improved from -0.96433 to -0.96546, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 9/50\n",
      "10000/10000 [==============================] - 1238s 124ms/step - loss: -0.9663 - iu_acc: 0.9156 - dice_acc: 0.9555 - accuracy: 0.9982 - val_loss: -0.9518 - val_iu_acc: 0.8705 - val_dice_acc: 0.9279 - val_accuracy: 0.9962\n",
      "\n",
      "Epoch 00009: loss improved from -0.96546 to -0.96633, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 10/50\n",
      "10000/10000 [==============================] - 1224s 122ms/step - loss: -0.9671 - iu_acc: 0.9169 - dice_acc: 0.9556 - accuracy: 0.9982 - val_loss: -0.9429 - val_iu_acc: 0.8656 - val_dice_acc: 0.9256 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00010: loss improved from -0.96633 to -0.96711, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 11/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9679 - iu_acc: 0.9203 - dice_acc: 0.9583 - accuracy: 0.9983 - val_loss: -0.9501 - val_iu_acc: 0.8665 - val_dice_acc: 0.9248 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00011: loss improved from -0.96711 to -0.96787, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 12/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9684 - iu_acc: 0.9211 - dice_acc: 0.9584 - accuracy: 0.9983 - val_loss: -0.9582 - val_iu_acc: 0.8826 - val_dice_acc: 0.9352 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00012: loss improved from -0.96787 to -0.96840, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 13/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9691 - iu_acc: 0.9219 - dice_acc: 0.9593 - accuracy: 0.9983 - val_loss: -0.9501 - val_iu_acc: 0.8776 - val_dice_acc: 0.9328 - val_accuracy: 0.9959\n",
      "\n",
      "Epoch 00013: loss improved from -0.96840 to -0.96906, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 14/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9695 - iu_acc: 0.9228 - dice_acc: 0.9595 - accuracy: 0.9984 - val_loss: -0.9474 - val_iu_acc: 0.8756 - val_dice_acc: 0.9314 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00014: loss improved from -0.96906 to -0.96948, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 15/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9702 - iu_acc: 0.9246 - dice_acc: 0.9610 - accuracy: 0.9984 - val_loss: -0.9437 - val_iu_acc: 0.8677 - val_dice_acc: 0.9264 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00015: loss improved from -0.96948 to -0.97021, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 16/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9704 - iu_acc: 0.9236 - dice_acc: 0.9601 - accuracy: 0.9984 - val_loss: -0.9501 - val_iu_acc: 0.8603 - val_dice_acc: 0.9204 - val_accuracy: 0.9958\n",
      "\n",
      "Epoch 00016: loss improved from -0.97021 to -0.97036, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 17/50\n",
      "10000/10000 [==============================] - 1236s 124ms/step - loss: -0.9710 - iu_acc: 0.9260 - dice_acc: 0.9620 - accuracy: 0.9984 - val_loss: -0.9428 - val_iu_acc: 0.8575 - val_dice_acc: 0.9196 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00017: loss improved from -0.97036 to -0.97103, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 18/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9710 - iu_acc: 0.9257 - dice_acc: 0.9616 - accuracy: 0.9984 - val_loss: -0.9426 - val_iu_acc: 0.8658 - val_dice_acc: 0.9245 - val_accuracy: 0.9953\n",
      "\n",
      "Epoch 00018: loss improved from -0.97103 to -0.97103, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 19/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9720 - iu_acc: 0.9272 - dice_acc: 0.9625 - accuracy: 0.9985 - val_loss: -0.9489 - val_iu_acc: 0.8615 - val_dice_acc: 0.9213 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00019: loss improved from -0.97103 to -0.97203, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 20/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9721 - iu_acc: 0.9286 - dice_acc: 0.9635 - accuracy: 0.9985 - val_loss: -0.9401 - val_iu_acc: 0.8588 - val_dice_acc: 0.9203 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00020: loss improved from -0.97203 to -0.97206, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 21/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9724 - iu_acc: 0.9303 - dice_acc: 0.9642 - accuracy: 0.9985 - val_loss: -0.9585 - val_iu_acc: 0.8894 - val_dice_acc: 0.9395 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00021: loss improved from -0.97206 to -0.97244, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 22/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9726 - iu_acc: 0.9297 - dice_acc: 0.9643 - accuracy: 0.9985 - val_loss: -0.9509 - val_iu_acc: 0.8743 - val_dice_acc: 0.9307 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00022: loss improved from -0.97244 to -0.97258, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 23/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9729 - iu_acc: 0.9305 - dice_acc: 0.9646 - accuracy: 0.9985 - val_loss: -0.9529 - val_iu_acc: 0.8864 - val_dice_acc: 0.9378 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00023: loss improved from -0.97258 to -0.97287, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 24/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9736 - iu_acc: 0.9309 - dice_acc: 0.9645 - accuracy: 0.9985 - val_loss: -0.9611 - val_iu_acc: 0.8393 - val_dice_acc: 0.8887 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00024: loss improved from -0.97287 to -0.97356, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 25/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9737 - iu_acc: 0.9320 - dice_acc: 0.9652 - accuracy: 0.9986 - val_loss: -0.9440 - val_iu_acc: 0.8671 - val_dice_acc: 0.9259 - val_accuracy: 0.9957\n",
      "\n",
      "Epoch 00025: loss improved from -0.97356 to -0.97375, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 26/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9739 - iu_acc: 0.9336 - dice_acc: 0.9662 - accuracy: 0.9986 - val_loss: -0.9470 - val_iu_acc: 0.8667 - val_dice_acc: 0.9243 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00026: loss improved from -0.97375 to -0.97390, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 27/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9742 - iu_acc: 0.9331 - dice_acc: 0.9662 - accuracy: 0.9986 - val_loss: -0.9606 - val_iu_acc: 0.8914 - val_dice_acc: 0.9401 - val_accuracy: 0.9970\n",
      "\n",
      "Epoch 00027: loss improved from -0.97390 to -0.97417, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 28/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9745 - iu_acc: 0.9338 - dice_acc: 0.9662 - accuracy: 0.9986 - val_loss: -0.9499 - val_iu_acc: 0.8830 - val_dice_acc: 0.9361 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00028: loss improved from -0.97417 to -0.97454, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 29/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9746 - iu_acc: 0.9339 - dice_acc: 0.9663 - accuracy: 0.9986 - val_loss: -0.9573 - val_iu_acc: 0.8881 - val_dice_acc: 0.9384 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00029: loss improved from -0.97454 to -0.97458, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 30/50\n",
      "10000/10000 [==============================] - 1224s 122ms/step - loss: -0.9750 - iu_acc: 0.9347 - dice_acc: 0.9673 - accuracy: 0.9986 - val_loss: -0.9564 - val_iu_acc: 0.8767 - val_dice_acc: 0.9308 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00030: loss improved from -0.97458 to -0.97502, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 31/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9749 - iu_acc: 0.9361 - dice_acc: 0.9672 - accuracy: 0.9986 - val_loss: -0.9476 - val_iu_acc: 0.8291 - val_dice_acc: 0.8925 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00031: loss did not improve from -0.97502\n",
      "Epoch 32/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9753 - iu_acc: 0.9360 - dice_acc: 0.9676 - accuracy: 0.9987 - val_loss: -0.9501 - val_iu_acc: 0.8556 - val_dice_acc: 0.9154 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00032: loss improved from -0.97502 to -0.97529, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 33/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9757 - iu_acc: 0.9371 - dice_acc: 0.9683 - accuracy: 0.9987 - val_loss: -0.9539 - val_iu_acc: 0.8745 - val_dice_acc: 0.9302 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00033: loss improved from -0.97529 to -0.97571, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 34/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9757 - iu_acc: 0.9374 - dice_acc: 0.9685 - accuracy: 0.9987 - val_loss: -0.9525 - val_iu_acc: 0.8760 - val_dice_acc: 0.9305 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00034: loss did not improve from -0.97571\n",
      "Epoch 35/50\n",
      "10000/10000 [==============================] - 1229s 123ms/step - loss: -0.9759 - iu_acc: 0.9379 - dice_acc: 0.9685 - accuracy: 0.9987 - val_loss: -0.9600 - val_iu_acc: 0.8575 - val_dice_acc: 0.9096 - val_accuracy: 0.9971\n",
      "\n",
      "Epoch 00035: loss improved from -0.97571 to -0.97589, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 36/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9762 - iu_acc: 0.9377 - dice_acc: 0.9688 - accuracy: 0.9987 - val_loss: -0.9588 - val_iu_acc: 0.8911 - val_dice_acc: 0.9405 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00036: loss improved from -0.97589 to -0.97617, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 37/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9762 - iu_acc: 0.9378 - dice_acc: 0.9689 - accuracy: 0.9987 - val_loss: -0.9551 - val_iu_acc: 0.8806 - val_dice_acc: 0.9342 - val_accuracy: 0.9966\n",
      "\n",
      "Epoch 00037: loss improved from -0.97617 to -0.97620, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 38/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9766 - iu_acc: 0.9385 - dice_acc: 0.9693 - accuracy: 0.9987 - val_loss: -0.9637 - val_iu_acc: 0.8372 - val_dice_acc: 0.8757 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00038: loss improved from -0.97620 to -0.97656, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 39/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9766 - iu_acc: 0.9400 - dice_acc: 0.9699 - accuracy: 0.9987 - val_loss: -0.9497 - val_iu_acc: 0.8187 - val_dice_acc: 0.8708 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00039: loss improved from -0.97656 to -0.97656, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 40/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9771 - iu_acc: 0.9402 - dice_acc: 0.9703 - accuracy: 0.9987 - val_loss: -0.9652 - val_iu_acc: 0.8985 - val_dice_acc: 0.9444 - val_accuracy: 0.9974\n",
      "\n",
      "Epoch 00040: loss improved from -0.97656 to -0.97710, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 41/50\n",
      "10000/10000 [==============================] - 1223s 122ms/step - loss: -0.9772 - iu_acc: 0.9387 - dice_acc: 0.9695 - accuracy: 0.9987 - val_loss: -0.9572 - val_iu_acc: 0.8749 - val_dice_acc: 0.9292 - val_accuracy: 0.9969\n",
      "\n",
      "Epoch 00041: loss improved from -0.97710 to -0.97718, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 42/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9774 - iu_acc: 0.9397 - dice_acc: 0.9701 - accuracy: 0.9988 - val_loss: -0.9547 - val_iu_acc: 0.8443 - val_dice_acc: 0.9015 - val_accuracy: 0.9965\n",
      "\n",
      "Epoch 00042: loss improved from -0.97718 to -0.97736, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 43/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9775 - iu_acc: 0.9406 - dice_acc: 0.9705 - accuracy: 0.9988 - val_loss: -0.9483 - val_iu_acc: 0.8591 - val_dice_acc: 0.9201 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00043: loss improved from -0.97736 to -0.97754, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 44/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9776 - iu_acc: 0.9423 - dice_acc: 0.9710 - accuracy: 0.9988 - val_loss: -0.9567 - val_iu_acc: 0.8762 - val_dice_acc: 0.9306 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00044: loss improved from -0.97754 to -0.97763, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 45/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9779 - iu_acc: 0.9418 - dice_acc: 0.9710 - accuracy: 0.9988 - val_loss: -0.9458 - val_iu_acc: 0.8345 - val_dice_acc: 0.8962 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00045: loss improved from -0.97763 to -0.97786, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9781 - iu_acc: 0.9424 - dice_acc: 0.9712 - accuracy: 0.9988 - val_loss: -0.9476 - val_iu_acc: 0.8621 - val_dice_acc: 0.9222 - val_accuracy: 0.9961\n",
      "\n",
      "Epoch 00046: loss improved from -0.97786 to -0.97806, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 47/50\n",
      "10000/10000 [==============================] - 1221s 122ms/step - loss: -0.9779 - iu_acc: 0.9412 - dice_acc: 0.9707 - accuracy: 0.9988 - val_loss: -0.9354 - val_iu_acc: 0.8519 - val_dice_acc: 0.9142 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00047: loss did not improve from -0.97806\n",
      "Epoch 48/50\n",
      "10000/10000 [==============================] - 1221s 122ms/step - loss: -0.9782 - iu_acc: 0.9423 - dice_acc: 0.9710 - accuracy: 0.9988 - val_loss: -0.9657 - val_iu_acc: 0.8839 - val_dice_acc: 0.9322 - val_accuracy: 0.9973\n",
      "\n",
      "Epoch 00048: loss improved from -0.97806 to -0.97822, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 49/50\n",
      "10000/10000 [==============================] - 1221s 122ms/step - loss: -0.9785 - iu_acc: 0.9429 - dice_acc: 0.9712 - accuracy: 0.9988 - val_loss: -0.9522 - val_iu_acc: 0.8768 - val_dice_acc: 0.9324 - val_accuracy: 0.9963\n",
      "\n",
      "Epoch 00049: loss improved from -0.97822 to -0.97854, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n",
      "Epoch 50/50\n",
      "10000/10000 [==============================] - 1222s 122ms/step - loss: -0.9787 - iu_acc: 0.9427 - dice_acc: 0.9717 - accuracy: 0.9988 - val_loss: -0.9394 - val_iu_acc: 0.8569 - val_dice_acc: 0.9192 - val_accuracy: 0.9954\n",
      "\n",
      "Epoch 00050: loss improved from -0.97854 to -0.97866, saving model to D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5\n"
     ]
    }
   ],
   "source": [
    "#%% training from scratch\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('D:/Anil/saved_model/UNet/UNET_Gray_mold_50epoch_10000_it.hdf5', monitor = 'loss', verbose = 1, save_best_only =True)\n",
    "callback_checkpoint = [model_checkpoint]\n",
    "\n",
    "model = get_unet()\n",
    "train_data = gen_train_data()\n",
    "test_data = test_data()\n",
    "history = model.fit_generator(train_data, steps_per_epoch=10000, epochs=50, verbose=1, \n",
    "                    shuffle=True, validation_data=test_data, callbacks = callback_checkpoint)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_unet(path_weight)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "Found 42 images belonging to 1 classes.\n",
      "Found 42 images belonging to 1 classes.\n",
      "5000/5000 [==============================] - 621s 124ms/step - loss: -0.6828 - iu_acc: 0.6783 - dice_acc: 0.7996 - accuracy: 0.9673 - val_loss: -0.6696 - val_iu_acc: 0.5194 - val_dice_acc: 0.6675 - val_accuracy: 0.9645\n",
      "\n",
      "Epoch 00001: loss improved from inf to -0.68279, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 2/80\n",
      "5000/5000 [==============================] - 615s 123ms/step - loss: -0.8623 - iu_acc: 0.7660 - dice_acc: 0.8663 - accuracy: 0.9819 - val_loss: -0.6930 - val_iu_acc: 0.5335 - val_dice_acc: 0.6792 - val_accuracy: 0.9664\n",
      "\n",
      "Epoch 00002: loss improved from -0.68279 to -0.86225, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 3/80\n",
      "5000/5000 [==============================] - 615s 123ms/step - loss: -0.8796 - iu_acc: 0.7837 - dice_acc: 0.8776 - accuracy: 0.9835 - val_loss: -0.7305 - val_iu_acc: 0.5684 - val_dice_acc: 0.7118 - val_accuracy: 0.9727\n",
      "\n",
      "Epoch 00003: loss improved from -0.86225 to -0.87961, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 4/80\n",
      "5000/5000 [==============================] - 615s 123ms/step - loss: -0.8898 - iu_acc: 0.7991 - dice_acc: 0.8874 - accuracy: 0.9851 - val_loss: -0.6986 - val_iu_acc: 0.5380 - val_dice_acc: 0.6839 - val_accuracy: 0.9661\n",
      "\n",
      "Epoch 00004: loss improved from -0.87961 to -0.88984, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 5/80\n",
      "5000/5000 [==============================] - 615s 123ms/step - loss: -0.8955 - iu_acc: 0.8079 - dice_acc: 0.8929 - accuracy: 0.9858 - val_loss: -0.6874 - val_iu_acc: 0.5235 - val_dice_acc: 0.6714 - val_accuracy: 0.9643\n",
      "\n",
      "Epoch 00005: loss improved from -0.88984 to -0.89545, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 6/80\n",
      "5000/5000 [==============================] - 616s 123ms/step - loss: -0.9002 - iu_acc: 0.8152 - dice_acc: 0.8974 - accuracy: 0.9865 - val_loss: -0.7165 - val_iu_acc: 0.5572 - val_dice_acc: 0.7018 - val_accuracy: 0.9691\n",
      "\n",
      "Epoch 00006: loss improved from -0.89545 to -0.90017, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 7/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9037 - iu_acc: 0.8210 - dice_acc: 0.9009 - accuracy: 0.9870 - val_loss: -0.7175 - val_iu_acc: 0.5593 - val_dice_acc: 0.7026 - val_accuracy: 0.9697\n",
      "\n",
      "Epoch 00007: loss improved from -0.90017 to -0.90372, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 8/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9060 - iu_acc: 0.8253 - dice_acc: 0.9035 - accuracy: 0.9874 - val_loss: -0.7641 - val_iu_acc: 0.6117 - val_dice_acc: 0.7478 - val_accuracy: 0.9767\n",
      "\n",
      "Epoch 00008: loss improved from -0.90372 to -0.90605, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 9/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9084 - iu_acc: 0.8286 - dice_acc: 0.9055 - accuracy: 0.9877 - val_loss: -0.7319 - val_iu_acc: 0.5725 - val_dice_acc: 0.7158 - val_accuracy: 0.9716\n",
      "\n",
      "Epoch 00009: loss improved from -0.90605 to -0.90844, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 10/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9104 - iu_acc: 0.8322 - dice_acc: 0.9077 - accuracy: 0.9881 - val_loss: -0.7208 - val_iu_acc: 0.5640 - val_dice_acc: 0.7075 - val_accuracy: 0.9695\n",
      "\n",
      "Epoch 00010: loss improved from -0.90844 to -0.91043, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 11/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9122 - iu_acc: 0.8348 - dice_acc: 0.9092 - accuracy: 0.9883 - val_loss: -0.7551 - val_iu_acc: 0.6061 - val_dice_acc: 0.7419 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00011: loss improved from -0.91043 to -0.91216, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 12/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9136 - iu_acc: 0.8373 - dice_acc: 0.9108 - accuracy: 0.9885 - val_loss: -0.7116 - val_iu_acc: 0.5557 - val_dice_acc: 0.7009 - val_accuracy: 0.9688\n",
      "\n",
      "Epoch 00012: loss improved from -0.91216 to -0.91362, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 13/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9147 - iu_acc: 0.8394 - dice_acc: 0.9120 - accuracy: 0.9886 - val_loss: -0.7491 - val_iu_acc: 0.5926 - val_dice_acc: 0.7340 - val_accuracy: 0.9740\n",
      "\n",
      "Epoch 00013: loss improved from -0.91362 to -0.91472, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 14/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9162 - iu_acc: 0.8418 - dice_acc: 0.9134 - accuracy: 0.9888 - val_loss: -0.7793 - val_iu_acc: 0.6342 - val_dice_acc: 0.7657 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 00014: loss improved from -0.91472 to -0.91618, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 15/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9175 - iu_acc: 0.8438 - dice_acc: 0.9147 - accuracy: 0.9890 - val_loss: -0.7583 - val_iu_acc: 0.6083 - val_dice_acc: 0.7446 - val_accuracy: 0.9752\n",
      "\n",
      "Epoch 00015: loss improved from -0.91618 to -0.91751, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 16/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9181 - iu_acc: 0.8449 - dice_acc: 0.9153 - accuracy: 0.9891 - val_loss: -0.7629 - val_iu_acc: 0.6151 - val_dice_acc: 0.7495 - val_accuracy: 0.9763\n",
      "\n",
      "Epoch 00016: loss improved from -0.91751 to -0.91808, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 17/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9194 - iu_acc: 0.8471 - dice_acc: 0.9166 - accuracy: 0.9893 - val_loss: -0.7609 - val_iu_acc: 0.6123 - val_dice_acc: 0.7474 - val_accuracy: 0.9759\n",
      "\n",
      "Epoch 00017: loss improved from -0.91808 to -0.91940, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 18/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9200 - iu_acc: 0.8485 - dice_acc: 0.9174 - accuracy: 0.9894 - val_loss: -0.7542 - val_iu_acc: 0.6051 - val_dice_acc: 0.7413 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00018: loss improved from -0.91940 to -0.92001, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 19/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9208 - iu_acc: 0.8494 - dice_acc: 0.9180 - accuracy: 0.9894 - val_loss: -0.7740 - val_iu_acc: 0.6278 - val_dice_acc: 0.7607 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00019: loss improved from -0.92001 to -0.92076, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 20/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9215 - iu_acc: 0.8510 - dice_acc: 0.9189 - accuracy: 0.9896 - val_loss: -0.7562 - val_iu_acc: 0.6057 - val_dice_acc: 0.7427 - val_accuracy: 0.9751\n",
      "\n",
      "Epoch 00020: loss improved from -0.92076 to -0.92149, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 21/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9223 - iu_acc: 0.8523 - dice_acc: 0.9197 - accuracy: 0.9896 - val_loss: -0.7304 - val_iu_acc: 0.5721 - val_dice_acc: 0.7165 - val_accuracy: 0.9709\n",
      "\n",
      "Epoch 00021: loss improved from -0.92149 to -0.92235, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 22/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9229 - iu_acc: 0.8534 - dice_acc: 0.9204 - accuracy: 0.9898 - val_loss: -0.7579 - val_iu_acc: 0.6102 - val_dice_acc: 0.7452 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00022: loss improved from -0.92235 to -0.92292, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 23/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9235 - iu_acc: 0.8543 - dice_acc: 0.9209 - accuracy: 0.9898 - val_loss: -0.7346 - val_iu_acc: 0.5917 - val_dice_acc: 0.7295 - val_accuracy: 0.9728\n",
      "\n",
      "Epoch 00023: loss improved from -0.92292 to -0.92349, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 24/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9240 - iu_acc: 0.8553 - dice_acc: 0.9214 - accuracy: 0.9899 - val_loss: -0.7713 - val_iu_acc: 0.6255 - val_dice_acc: 0.7580 - val_accuracy: 0.9773\n",
      "\n",
      "Epoch 00024: loss improved from -0.92349 to -0.92403, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 25/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9246 - iu_acc: 0.8564 - dice_acc: 0.9221 - accuracy: 0.9900 - val_loss: -0.7696 - val_iu_acc: 0.6253 - val_dice_acc: 0.7569 - val_accuracy: 0.9769\n",
      "\n",
      "Epoch 00025: loss improved from -0.92403 to -0.92463, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 26/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9251 - iu_acc: 0.8573 - dice_acc: 0.9227 - accuracy: 0.9900 - val_loss: -0.7563 - val_iu_acc: 0.6125 - val_dice_acc: 0.7452 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00026: loss improved from -0.92463 to -0.92506, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 27/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9254 - iu_acc: 0.8579 - dice_acc: 0.9230 - accuracy: 0.9901 - val_loss: -0.7890 - val_iu_acc: 0.6511 - val_dice_acc: 0.7771 - val_accuracy: 0.9795\n",
      "\n",
      "Epoch 00027: loss improved from -0.92506 to -0.92542, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 28/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9261 - iu_acc: 0.8590 - dice_acc: 0.9236 - accuracy: 0.9902 - val_loss: -0.7894 - val_iu_acc: 0.6501 - val_dice_acc: 0.7770 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00028: loss improved from -0.92542 to -0.92611, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 29/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9264 - iu_acc: 0.8595 - dice_acc: 0.9239 - accuracy: 0.9903 - val_loss: -0.7510 - val_iu_acc: 0.6034 - val_dice_acc: 0.7387 - val_accuracy: 0.9745\n",
      "\n",
      "Epoch 00029: loss improved from -0.92611 to -0.92639, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 30/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9269 - iu_acc: 0.8602 - dice_acc: 0.9243 - accuracy: 0.9903 - val_loss: -0.1629 - val_iu_acc: 0.0895 - val_dice_acc: 0.1597 - val_accuracy: 0.5321\n",
      "\n",
      "Epoch 00030: loss improved from -0.92639 to -0.92688, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 31/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9271 - iu_acc: 0.8608 - dice_acc: 0.9246 - accuracy: 0.9903 - val_loss: -0.7790 - val_iu_acc: 0.6357 - val_dice_acc: 0.7661 - val_accuracy: 0.9782\n",
      "\n",
      "Epoch 00031: loss improved from -0.92688 to -0.92706, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 32/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9277 - iu_acc: 0.8618 - dice_acc: 0.9253 - accuracy: 0.9904 - val_loss: -0.7738 - val_iu_acc: 0.6285 - val_dice_acc: 0.7604 - val_accuracy: 0.9774\n",
      "\n",
      "Epoch 00032: loss improved from -0.92706 to -0.92772, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 33/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9280 - iu_acc: 0.8624 - dice_acc: 0.9256 - accuracy: 0.9904 - val_loss: -0.7873 - val_iu_acc: 0.6467 - val_dice_acc: 0.7746 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00033: loss improved from -0.92772 to -0.92803, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 34/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9283 - iu_acc: 0.8630 - dice_acc: 0.9260 - accuracy: 0.9904 - val_loss: -0.7527 - val_iu_acc: 0.6026 - val_dice_acc: 0.7395 - val_accuracy: 0.9744\n",
      "\n",
      "Epoch 00034: loss improved from -0.92803 to -0.92826, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 35/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9287 - iu_acc: 0.8633 - dice_acc: 0.9261 - accuracy: 0.9905 - val_loss: -0.7546 - val_iu_acc: 0.6069 - val_dice_acc: 0.7421 - val_accuracy: 0.9747\n",
      "\n",
      "Epoch 00035: loss improved from -0.92826 to -0.92869, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 36/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9290 - iu_acc: 0.8642 - dice_acc: 0.9267 - accuracy: 0.9905 - val_loss: -0.7829 - val_iu_acc: 0.6390 - val_dice_acc: 0.7694 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00036: loss improved from -0.92869 to -0.92904, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 37/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9291 - iu_acc: 0.8643 - dice_acc: 0.9267 - accuracy: 0.9906 - val_loss: -0.7766 - val_iu_acc: 0.6325 - val_dice_acc: 0.7637 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00037: loss improved from -0.92904 to -0.92911, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 38/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9298 - iu_acc: 0.8655 - dice_acc: 0.9274 - accuracy: 0.9907 - val_loss: -0.7704 - val_iu_acc: 0.6224 - val_dice_acc: 0.7568 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00038: loss improved from -0.92911 to -0.92979, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 39/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9297 - iu_acc: 0.8655 - dice_acc: 0.9274 - accuracy: 0.9906 - val_loss: -0.7826 - val_iu_acc: 0.6410 - val_dice_acc: 0.7701 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00039: loss did not improve from -0.92979\n",
      "Epoch 40/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9301 - iu_acc: 0.8661 - dice_acc: 0.9278 - accuracy: 0.9908 - val_loss: -0.7597 - val_iu_acc: 0.6112 - val_dice_acc: 0.7466 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00040: loss improved from -0.92979 to -0.93011, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 41/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9299 - iu_acc: 0.8660 - dice_acc: 0.9277 - accuracy: 0.9907 - val_loss: -0.7705 - val_iu_acc: 0.6289 - val_dice_acc: 0.7590 - val_accuracy: 0.9771\n",
      "\n",
      "Epoch 00041: loss did not improve from -0.93011\n",
      "Epoch 42/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9305 - iu_acc: 0.8668 - dice_acc: 0.9282 - accuracy: 0.9908 - val_loss: -0.7551 - val_iu_acc: 0.6081 - val_dice_acc: 0.7428 - val_accuracy: 0.9748\n",
      "\n",
      "Epoch 00042: loss improved from -0.93011 to -0.93045, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 43/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9308 - iu_acc: 0.8673 - dice_acc: 0.9284 - accuracy: 0.9908 - val_loss: -0.7818 - val_iu_acc: 0.6388 - val_dice_acc: 0.7688 - val_accuracy: 0.9784\n",
      "\n",
      "Epoch 00043: loss improved from -0.93045 to -0.93083, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 44/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9310 - iu_acc: 0.8677 - dice_acc: 0.9287 - accuracy: 0.9908 - val_loss: -0.7633 - val_iu_acc: 0.6178 - val_dice_acc: 0.7509 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00044: loss improved from -0.93083 to -0.93098, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 45/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9309 - iu_acc: 0.8678 - dice_acc: 0.9287 - accuracy: 0.9909 - val_loss: -0.7870 - val_iu_acc: 0.6445 - val_dice_acc: 0.7740 - val_accuracy: 0.9791\n",
      "\n",
      "Epoch 00045: loss did not improve from -0.93098\n",
      "Epoch 46/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9314 - iu_acc: 0.8684 - dice_acc: 0.9291 - accuracy: 0.9909 - val_loss: -0.7879 - val_iu_acc: 0.6457 - val_dice_acc: 0.7745 - val_accuracy: 0.9790\n",
      "\n",
      "Epoch 00046: loss improved from -0.93098 to -0.93139, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 47/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9316 - iu_acc: 0.8688 - dice_acc: 0.9293 - accuracy: 0.9909 - val_loss: -0.7584 - val_iu_acc: 0.6151 - val_dice_acc: 0.7472 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00047: loss improved from -0.93139 to -0.93163, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 48/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9319 - iu_acc: 0.8691 - dice_acc: 0.9295 - accuracy: 0.9910 - val_loss: -0.7599 - val_iu_acc: 0.6075 - val_dice_acc: 0.7451 - val_accuracy: 0.9754\n",
      "\n",
      "Epoch 00048: loss improved from -0.93163 to -0.93189, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 49/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9319 - iu_acc: 0.8692 - dice_acc: 0.9296 - accuracy: 0.9910 - val_loss: -0.7609 - val_iu_acc: 0.6141 - val_dice_acc: 0.7490 - val_accuracy: 0.9753\n",
      "\n",
      "Epoch 00049: loss improved from -0.93189 to -0.93192, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 50/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9323 - iu_acc: 0.8698 - dice_acc: 0.9299 - accuracy: 0.9910 - val_loss: -0.7382 - val_iu_acc: 0.5906 - val_dice_acc: 0.7277 - val_accuracy: 0.9721\n",
      "\n",
      "Epoch 00050: loss improved from -0.93192 to -0.93226, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 51/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9323 - iu_acc: 0.8700 - dice_acc: 0.9300 - accuracy: 0.9910 - val_loss: -0.7655 - val_iu_acc: 0.6187 - val_dice_acc: 0.7531 - val_accuracy: 0.9759\n",
      "\n",
      "Epoch 00051: loss improved from -0.93226 to -0.93228, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 52/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9323 - iu_acc: 0.8700 - dice_acc: 0.9300 - accuracy: 0.9911 - val_loss: -0.7660 - val_iu_acc: 0.6216 - val_dice_acc: 0.7539 - val_accuracy: 0.9765\n",
      "\n",
      "Epoch 00052: loss improved from -0.93228 to -0.93228, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 53/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9327 - iu_acc: 0.8707 - dice_acc: 0.9304 - accuracy: 0.9911 - val_loss: -0.7714 - val_iu_acc: 0.6249 - val_dice_acc: 0.7586 - val_accuracy: 0.9767\n",
      "\n",
      "Epoch 00053: loss improved from -0.93228 to -0.93266, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 54/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9327 - iu_acc: 0.8709 - dice_acc: 0.9305 - accuracy: 0.9911 - val_loss: -0.7743 - val_iu_acc: 0.6293 - val_dice_acc: 0.7614 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00054: loss improved from -0.93266 to -0.93272, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 55/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9329 - iu_acc: 0.8712 - dice_acc: 0.9307 - accuracy: 0.9911 - val_loss: -0.7608 - val_iu_acc: 0.6092 - val_dice_acc: 0.7455 - val_accuracy: 0.9757\n",
      "\n",
      "Epoch 00055: loss improved from -0.93272 to -0.93290, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 56/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9331 - iu_acc: 0.8714 - dice_acc: 0.9308 - accuracy: 0.9912 - val_loss: -0.7803 - val_iu_acc: 0.6359 - val_dice_acc: 0.7670 - val_accuracy: 0.9782\n",
      "\n",
      "Epoch 00056: loss improved from -0.93290 to -0.93312, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 57/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9333 - iu_acc: 0.8720 - dice_acc: 0.9312 - accuracy: 0.9912 - val_loss: -0.7278 - val_iu_acc: 0.5674 - val_dice_acc: 0.7123 - val_accuracy: 0.9703\n",
      "\n",
      "Epoch 00057: loss improved from -0.93312 to -0.93334, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 58/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9334 - iu_acc: 0.8718 - dice_acc: 0.9311 - accuracy: 0.9912 - val_loss: -0.7770 - val_iu_acc: 0.6298 - val_dice_acc: 0.7631 - val_accuracy: 0.9776\n",
      "\n",
      "Epoch 00058: loss improved from -0.93334 to -0.93339, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 59/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9336 - iu_acc: 0.8723 - dice_acc: 0.9313 - accuracy: 0.9912 - val_loss: -0.7722 - val_iu_acc: 0.6250 - val_dice_acc: 0.7588 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00059: loss improved from -0.93339 to -0.93363, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 60/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9337 - iu_acc: 0.8724 - dice_acc: 0.9314 - accuracy: 0.9913 - val_loss: -0.4465 - val_iu_acc: 0.2852 - val_dice_acc: 0.4280 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00060: loss improved from -0.93363 to -0.93368, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 61/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9337 - iu_acc: 0.8726 - dice_acc: 0.9315 - accuracy: 0.9912 - val_loss: -0.7728 - val_iu_acc: 0.6234 - val_dice_acc: 0.7580 - val_accuracy: 0.9772\n",
      "\n",
      "Epoch 00061: loss improved from -0.93368 to -0.93370, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 62/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9341 - iu_acc: 0.8733 - dice_acc: 0.9319 - accuracy: 0.9913 - val_loss: -0.7706 - val_iu_acc: 0.6250 - val_dice_acc: 0.7579 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00062: loss improved from -0.93370 to -0.93414, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 63/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9343 - iu_acc: 0.8733 - dice_acc: 0.9319 - accuracy: 0.9913 - val_loss: -0.7647 - val_iu_acc: 0.6152 - val_dice_acc: 0.7501 - val_accuracy: 0.9761\n",
      "\n",
      "Epoch 00063: loss improved from -0.93414 to -0.93428, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 64/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9342 - iu_acc: 0.8734 - dice_acc: 0.9320 - accuracy: 0.9913 - val_loss: -0.7368 - val_iu_acc: 0.5785 - val_dice_acc: 0.7212 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00064: loss did not improve from -0.93428\n",
      "Epoch 65/80\n",
      "5000/5000 [==============================] - 608s 122ms/step - loss: -0.9343 - iu_acc: 0.8736 - dice_acc: 0.9321 - accuracy: 0.9913 - val_loss: -0.7891 - val_iu_acc: 0.6450 - val_dice_acc: 0.7751 - val_accuracy: 0.9793\n",
      "\n",
      "Epoch 00065: loss improved from -0.93428 to -0.93429, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 66/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9345 - iu_acc: 0.8739 - dice_acc: 0.9323 - accuracy: 0.9914 - val_loss: -0.7762 - val_iu_acc: 0.6283 - val_dice_acc: 0.7618 - val_accuracy: 0.9775\n",
      "\n",
      "Epoch 00066: loss improved from -0.93429 to -0.93450, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 67/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9347 - iu_acc: 0.8743 - dice_acc: 0.9325 - accuracy: 0.9914 - val_loss: -0.7821 - val_iu_acc: 0.6412 - val_dice_acc: 0.7700 - val_accuracy: 0.9783\n",
      "\n",
      "Epoch 00067: loss improved from -0.93450 to -0.93468, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 68/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9347 - iu_acc: 0.8742 - dice_acc: 0.9324 - accuracy: 0.9914 - val_loss: -0.7716 - val_iu_acc: 0.6270 - val_dice_acc: 0.7590 - val_accuracy: 0.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00068: loss improved from -0.93468 to -0.93471, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 69/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9349 - iu_acc: 0.8745 - dice_acc: 0.9326 - accuracy: 0.9914 - val_loss: -0.7826 - val_iu_acc: 0.6398 - val_dice_acc: 0.7694 - val_accuracy: 0.9785\n",
      "\n",
      "Epoch 00069: loss improved from -0.93471 to -0.93486, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 70/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9350 - iu_acc: 0.8749 - dice_acc: 0.9328 - accuracy: 0.9915 - val_loss: -0.7367 - val_iu_acc: 0.5806 - val_dice_acc: 0.7223 - val_accuracy: 0.9717\n",
      "\n",
      "Epoch 00070: loss improved from -0.93486 to -0.93501, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 71/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9348 - iu_acc: 0.8746 - dice_acc: 0.9327 - accuracy: 0.9914 - val_loss: -0.7413 - val_iu_acc: 0.5832 - val_dice_acc: 0.7250 - val_accuracy: 0.9724\n",
      "\n",
      "Epoch 00071: loss did not improve from -0.93501\n",
      "Epoch 72/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9353 - iu_acc: 0.8754 - dice_acc: 0.9331 - accuracy: 0.9914 - val_loss: -0.7325 - val_iu_acc: 0.5713 - val_dice_acc: 0.7158 - val_accuracy: 0.9711\n",
      "\n",
      "Epoch 00072: loss improved from -0.93501 to -0.93533, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 73/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9354 - iu_acc: 0.8752 - dice_acc: 0.9330 - accuracy: 0.9914 - val_loss: -0.7827 - val_iu_acc: 0.6392 - val_dice_acc: 0.7693 - val_accuracy: 0.9786\n",
      "\n",
      "Epoch 00073: loss improved from -0.93533 to -0.93539, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 74/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9352 - iu_acc: 0.8751 - dice_acc: 0.9330 - accuracy: 0.9914 - val_loss: -0.7731 - val_iu_acc: 0.6258 - val_dice_acc: 0.7597 - val_accuracy: 0.9768\n",
      "\n",
      "Epoch 00074: loss did not improve from -0.93539\n",
      "Epoch 75/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9355 - iu_acc: 0.8756 - dice_acc: 0.9333 - accuracy: 0.9915 - val_loss: -0.7288 - val_iu_acc: 0.5672 - val_dice_acc: 0.7121 - val_accuracy: 0.9705\n",
      "\n",
      "Epoch 00075: loss improved from -0.93539 to -0.93554, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 76/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9356 - iu_acc: 0.8757 - dice_acc: 0.9333 - accuracy: 0.9915 - val_loss: -0.7696 - val_iu_acc: 0.6210 - val_dice_acc: 0.7560 - val_accuracy: 0.9764\n",
      "\n",
      "Epoch 00076: loss improved from -0.93554 to -0.93561, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 77/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9354 - iu_acc: 0.8756 - dice_acc: 0.9332 - accuracy: 0.9915 - val_loss: -0.7801 - val_iu_acc: 0.6353 - val_dice_acc: 0.7674 - val_accuracy: 0.9778\n",
      "\n",
      "Epoch 00077: loss did not improve from -0.93561\n",
      "Epoch 78/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9357 - iu_acc: 0.8759 - dice_acc: 0.9334 - accuracy: 0.9915 - val_loss: -0.7875 - val_iu_acc: 0.6460 - val_dice_acc: 0.7745 - val_accuracy: 0.9792\n",
      "\n",
      "Epoch 00078: loss improved from -0.93561 to -0.93571, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n",
      "Epoch 79/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9357 - iu_acc: 0.8760 - dice_acc: 0.9335 - accuracy: 0.9915 - val_loss: -0.7858 - val_iu_acc: 0.6425 - val_dice_acc: 0.7726 - val_accuracy: 0.9787\n",
      "\n",
      "Epoch 00079: loss did not improve from -0.93571\n",
      "Epoch 80/80\n",
      "5000/5000 [==============================] - 609s 122ms/step - loss: -0.9359 - iu_acc: 0.8763 - dice_acc: 0.9337 - accuracy: 0.9916 - val_loss: -0.7856 - val_iu_acc: 0.6394 - val_dice_acc: 0.7713 - val_accuracy: 0.9789\n",
      "\n",
      "Epoch 00080: loss improved from -0.93571 to -0.93591, saving model to D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5\n"
     ]
    }
   ],
   "source": [
    "#%% continue to train from weight\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('D:/Anil/saved_model/UNet/UNET_pretrained_Gray_mold_80epochs.hdf5', monitor = 'loss', verbose = 1, save_best_only =True)\n",
    "callback_checkpoint = [model_checkpoint]\n",
    "\n",
    "# model = get_unet(path_weight)\n",
    "\n",
    "train_data = gen_train_data()\n",
    "test_data = test_data()\n",
    "history = model.fit_generator(train_data, steps_per_epoch=5000, epochs=80, verbose=1, \n",
    "                    shuffle=True, validation_data=test_data, callbacks = callback_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "filepath=\"D:/Anil/saved_model/UNet/UNET_Dropout_50e_10000it_Gray_mold.hdf5\"\n",
    "model.save(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"D:/Anil/saved_model/UNet/UNET_Dropout_weights_50e_10000it_Gray_mold.h5\"\n",
    "model.save_weights(weight_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('D:/Anil/saved_model/UNet/loss_acc_history.json', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = np.array(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "history_dict = pd.DataFrame(history.history) \n",
    "hist_csv_file = \"D:/Anil/saved_model/UNet/model_dropout_history_50epochs_10000_it.csv\"\n",
    "with open(hist_csv_file, mode='w', newline = '') as f:\n",
    "    history_dict.to_csv(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "iu_acc = history.history['iu_acc']\n",
    "dice_acc = history.history['dice_acc']\n",
    "loss = history.history['loss']\n",
    "\n",
    "# testing accuracy and loss\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_iu_acc = loss = history.history['val_iu_acc']\n",
    "val_dice_acc = loss = history.history['val_dice_acc']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAABXcElEQVR4nO2deXxU5fW4n5MQCDsoCAgoCAiCAiKg4i4qaN3QKlj3pVhb97Zu3Wytv1qXr/tSt6qtVq0Vd3FFcZdFFEFQRNn3fUtCkvP749xLbsLMZCaZSSbJeT6fm7u9973vnczc857lPa+oKo7jOI6TLDm13QDHcRynbuGCw3Ecx0kJFxyO4zhOSrjgcBzHcVLCBYfjOI6TEi44HMdxnJRwweHUK0TkdRE5O91l6zMicr2I/DvOuUNFZGFNt8nJbhrVdgMcR0Q2RnabAYVASbB/oao+mWxdqnp0Jso6jlOGCw6n1lHVFuG2iPwIXKCqb1csJyKNVLW4JtvmOM72uKnKyVpCM4mIXC0iS4F/ikhbEXlFRFaIyJpgu0vkmvdE5IJg+xwR+VBEbg3K/iAiR1exbHcRmSgiG0TkbRG5N4F5p7I27iAi/xSRxcH5FyLnThCRaSKyXkS+F5GRce5xTXB+g4jMFJFRkXPJPMv7wbVvAe1S+J/sEXxua0VkhogcHzl3TNCWDSKySER+ExxvF3wGa0VktYh8ICL+7qnD+D/PyXY6AjsAuwJjse/sP4P9XYAtwD0Jrt8XmI29HG8GHhERqULZp4DPgR2B64EzE9yzsjb+CzPJ9QN2Am4HEJGhwBPAb4E2wMHAj3Hu8T1wENAa+DPwbxHplMKzTAnO3QAk6xPKA14G3gzafQnwpIj0Doo8gpkWWwJ7Au8Gx38NLATaAx2A6wDPdVSXUVVffMmaBXtRHhFsHwoUAfkJyg8E1kT238NMXQDnAHMi55phL6yOqZTFXv7FQLPI+X8D/07ymba1EegElAJtY5T7B3B7FT+3acAJKTxL88j5p+I9S/A/WBhsHwQsBXIi5/8DXB9szwcuBFpVqOMvwItAz9r+fvmSnsU1DifbWaGqBeGOiDQTkX+IyDwRWQ9MBNqISG6c65eGG6q6OdhskWLZnYHVkWMAC+I1uJI2dg3qWhPj0q6YJlEpInJWYNJaKyJrsR5+1OSU6FnWqOqmSNl5ydwzuHaBqpZWuLZzsH0ycAwwLzCF7R8cvwWYA7wpInNF5Jok7+dkKS44nGynoknj10BvYF9VbYWZcwDimZ/SwRJgBxFpFjnWNUH5RG1cENTVJsZ1C4AelTVGRHYFHgIuBnZU1TbA1yT3GSwB2opI88ixXZK4DmAx0LWCf2IXYBGAqk5S1RMwM9YLwLPB8Q2q+mtV3Q04DrhSRIYneU8nC3HB4dQ1WmI+g7UisgPwp0zfUFXnAZOB60WkcdCTPq4qbVTVJcDrwH2BEz1PRELB8ghwrogMF5EcEeksIn1i1N8cE6grAETkXEzjSOVZ/hw8y4GVPEuUz4BNwFVBuw8Nrn06qOt0EWmtqluB9QQh1SJyrIj0DHws4fGSmHdw6gQuOJy6xh1AU2Al8CkwvobuezqwP7AK+CvwDDbeJBZ3kLiNZwJbgVnAcuByAFX9HDgXc5avA97HHOzlUNWZwG3AJ8AyYC/goxSe5WeY83w1JtSeSOYiVS0CjgeODp7tPuAsVZ0Vea4fA/PcL4AzguO9gLeBjUGb71PV91Jor5NliKoHNzhOqojIM8AsVc24xuM42YZrHI6TBCIyRER6BCakkcAJmB3fcRocPnLccZKjI/A8No5jIXCRqn5Ru01ynNrBTVWO4zhOSripynEcx0mJBmGqateunXbr1q22m+E4jlOnmDJlykpVbV/xeIMQHN26dWPy5Mm13QzHcZw6hYjEzCrgpirHcRwnJVxwOI7jOCnhgsNxHMdJCRccjuM4TkpkTHCIyKMislxEvo5zXkTkLhGZIyJficigyLmRIjI7OHdN5PgOIvKWiHwXrNtmqv2O4zhObDKpcTwGxJz2MuBoLPlZL2xmt/sBgjkL7g3O9wVOE5G+wTXXAO+oai/gnWDfcRzHqUEyJjhUdSKWfTMeJwBPqPEpNtFNJ2AoNnvZ3CAb59NB2fCax4Ptx4ETM9J4x3EcJy61OY6jM+VnUVsYHIt1fN9gu0MwnwGqukREdopXuYiMxTQZdtkl2XlqnJpAVSnVUjQyR5MEcxCF02KrKopmdB22ITxWqqUJywPb2hwvVU90OvPwHuFSoiXbtuN9LpXdO9Z2zLoSPHtl9654ffR5Y+1XvDbW5xH+f1O9R6L/T6Lnruwzqvh/SuZZKt4j0f8mWm9l9cT6LOJeU8l3JHr/kDP7n0mvHXslrDdValNwxJqtTBMcTwlVfRB4EGDw4MFpT8hVVFLElq1bKCgu2LYUlhRSUFxAUUnRtqWwuHDb9tbSrRSXFm+3bC3ZytbSrTHX0RfOtnVp7P3wWElpSblz4Xb0RRb9IUZfbuHxbfuRF2zFY7GuCT777b7U0fZU9uNwHKd6SOQ1OqzrsHolOBZSfvrNLtjUlI3jHAdYJiKdAm2jEzYJTo2yeetmrn7rau6bfF/cnmNVEYS83DzycvLIy82jUU4jciWX3JxcciWXHMkhNydYV9gPl2j53BxbGkvjcmVExNYIIrKtrvB4eK5i+RzKl4mWi9YJ1qML64+2LWxzruSW0y6gfE8ten111jnBLKexzkc/g+h2onVYV/j/ihJLIIbPvO0zyMndVl+870Bl9461HbOuBM+S6N6x2hF93lj7FdtZ8f8Z7sd7nkT3iPX/yZH4VvbKPqPo/yn6XUv0LPHukeh/E32eVNoa7/+z7ZoU/qeZojYFx0vAxSLyNGaKWhcIhBVALxHpjs1lPAabsSy85mzgpmD9Yk02eMriKZz+/OnMXjWbC/a+gL7t+5LfKJ8mjZqQ3yjftnOb0KRRExrnNt5uycsxYRAKheiSl5NHbk5uTT6O4zhOlciY4BCR/wCHAu1EZCE2RWUegKo+ALwGHAPMATZjU2aiqsUicjHwBpALPKqqM4JqbwKeFZHzgfnAKZlqf5Ti0mJu+vAm/vz+n+nQvANvn/k2w3cbXhO3dhzHyToaxHwcgwcP1qomOfx+9fecOe5MPln4CWP2HMN9x9xH26Y+fMRxnPqPiExR1cEVjzeI7LhV5fFpj3Px6xeTK7k8edKT/Gyvn1V+keM4Tj3HBUcCVm1ZxZCdh/DYiY+xS2sP6XUcxwE3VSUkjJpKFMHhOI5TX3FTVRVwgeE4jrM9/mZ0HMdxUsIFh+M4jpMSLjgcx3GclHDB4TiO46SECw7HcRwnJVxwOI7jOCnhgsNxHMdJCRccjuM4Tkq44HAcx3FSwgWH4ziOkxIuOBzHcZyUcMHhOI7jpIQLDsdxHCclXHA4juM4KeGCw3Ecx0kJFxyO4zhOSmRUcIjISBGZLSJzROSaGOfbisg4EflKRD4XkT2D471FZFpkWS8ilwfnrheRRZFzx2TyGRzHcZzyZGwGQBHJBe4FjgQWApNE5CVVnRkpdh0wTVVHiUifoPxwVZ0NDIzUswgYF7nudlW9NVNtdxzHceKTSY1jKDBHVeeqahHwNHBChTJ9gXcAVHUW0E1EOlQoMxz4XlXnZbCtjuM4TpJkUnB0BhZE9hcGx6J8CZwEICJDgV2BLhXKjAH+U+HYxYF561ERaRvr5iIyVkQmi8jkFStWVPUZHMdxnApkUnBIjGNaYf8moK2ITAMuAb4AirdVINIYOB74b+Sa+4EemClrCXBbrJur6oOqOlhVB7dv376Kj+A4juNUJGM+DkzD6BrZ7wIsjhZQ1fXAuQAiIsAPwRJyNDBVVZdFrtm2LSIPAa+kveWO4zhOXDIpOCYBvUSkO+bcHgP8LFpARNoAmwMfyAXAxECYhJxGBTOViHRS1SXB7ijg68w033Ecp46gCiUlUFQMRVvLL53aQdP8tN4uY4JDVYtF5GLgDSAXeFRVZ4jIL4LzDwB7AE+ISAkwEzg/vF5EmmERWRdWqPpmERmImb1+jHHecRwn/ahCSSls3Wov6HBdtNW2i0viXAeUltqLvSRYl5badqNG0CQPGudBk8bBdmMz9JeUWp0lwVIcXFvuWFBncTGUVvQEACLQpmXaBYeoxrhZPWPw4ME6efLk2m6G4zjpRtVemgVbobDIXuLFxfZCLS6GrcG6tBTym0DTJvYSbZoPzZrYi1vVri0osnW4vXUrbC22pbjE1vHel41yra5Ynl2AnBzIzYHc3LJ1jlj7ioqgMNAOEr2PG+XaddvWOeX3G+dtvzTKNeFRRURkiqoO3q4pVa7RcRynuqjaS71UbVu1/Hb44t5aXP5FXrS17CUfr6fdKBfyGtk6JwfWb4Tlq8uXa5QbW1No1AgaN7Lrm+Xbfl50ybPzjfNsPycNcUbh8xZuBTQiFHKs/moIgHTjgsNxnORQtZdaQQFsKbKefElp8OIvLTO/hC99Da4hsh01uYSmm1TIDYRB40bQohns2CYw8UTMPHm58V+0paWwpRC2FNi6oNCEQn5QR7jOza3+55UqImWaQpbjgsNxGgKqZn4pKLR9Cf7Itp0ym3lo5gm3CwtNUBQUxjaliJSZYnJyzAQTvrQlcg8Re+nn55aZbEIzi0jZdeGSI2UmmLCnX92efU4ONG9qi1NlXHA4TrYQvpRTNUmoll9K1Uw5GzdHli0mGFIhNPc0aWwv2nZtyvwE+U2s159lJhSnZnDB4Ti1wdbi8i/2DZvNfBIl2msvh5ZbJXSo5uRAi6bQYQcz7WyLromakgJCm3q4uFBw4uCCw3GqQtizLymx7fAlGzW3lJSU2dGj680F5tQNadLYXurt29p14cu84jpK9IWeU8G8Izlm1mnRzLQDf/k7acYFh9NwKS01u3/4Ui8otBd61LEbfXmX8wGUJO7px6JRrpl4WrUwLaBlc3u55/nP0Klb+DfWqf+EcfobN8OGTWYW2rwlCHuMkCPW+486aKOO3UaNID+/vDknN9fKxAonzc0p7xNwAeHUE/yb7NQdSkvLXuiJymwuMMGwcUuZD2FrcVmZ5k2hTavyL/X8xha942Ydx6kUFxxOdlNcAivX2MCtNevLYt3DWP68YLuwCDZtMbNTNDqpWT7s2BpaNIeWzaB5M9MEHMepMi44nJpD1bSB1etsKdpqL/bmTaFZEFvftImVXb0elq+CVWvN9JPfGLp0MGFQtLVsJPGmAttu3MiEQrs2QZx+4BhOx4hex3HK4YLDyQyhrb+0FNZvgtVrTVgUBNFEzZtaaOimLbBybdl1YWRQmACuYzvYaUdo1dzNSI6TJbjgcFInTD2xKfAfbNpiS3FJ+bQTUXJyLEtn146wQ2vzK4SEfolt9RRbKom2rVxjcJwsxAWHUx5VWBaYiKIDxMJ1Sak5nqOJ4fKbmAYRjiQO006E283yTWjEEwI5ORaW2qJZJp/McZw04YLDMVRhxRr4cbGNYM5vbOGmFfMZ5YgNVGvezMYiNG8WlHMcp6HggqOho2q+hx8XWfhqs3zo28OczO5TcBwnBi446julpbB2Q9kkMdER0aoW6rp+k5mb+nSHnXZwgeE4TkJccNQ1li+Hv/0Nrr8eWreOXUbVhMWK1WZ+ijelJdiYiF67Qscd3RHtOE5SuOCoa7z1Ftxxh23ffnvZ8TDsdeUaExZFW00QtGsD7Xcw53WYQiOaUiPXM6A6jpMaLjjqGkuX2vruu+Gno6HLLqZdrN9UlpJjxzawU1sLe62Nmcwcx6nXuOCoCxSX2PiGzVvgm28tzUbTZvCrX8EdD1gYa6d20LqljX3wKCfHcTJIRgWHiIwE7gRygYdV9aYK59sCjwI9gALgPFX9Ojj3I7ABKAGKVXVwcHwH4BmgG/AjcKqqrsnkc9Q4mwvM5LRuowmM6NwNCxdBu/bwy4vhD9fBwm/hjNNrr62O4zQ4RFOdUyDZikVygW+BI4GFwCTgNFWdGSlzC7BRVf8sIn2Ae1V1eHDuR2Cwqq6sUO/NwGpVvUlErgHaqurVidoyePBgnTx5chqfLs2omqlp1VpLvxHOBNcs37SJaC6nE46D9evho49g6FAzXc2aBS1b1uYTOI5TDxGRKWGnPUomNY6hwBxVnRs04GngBGBmpExf4G8AqjpLRLqJSAdVXZag3hOAQ4Ptx4H3gISCI2vZUgiLllnm163F5p9o3QI672QZXaNpOUKWLYNu3cx3ce+9sP/+8Ne/wt//XuPNdxynYZLJ+MvOwILI/sLgWJQvgZMARGQosCvQJTinwJsiMkVExkau6aCqSwCC9U6xbi4iY0VksohMXrFiRbUfJq1s2AQz58Ln02HxCkvHsUd3GDYABvQ2wRFLaIBpGB072vZ++8G551p01axZNdd+x3EaNJkUHLFiPCvaxW4C2orINOAS4AsgnHHnAFUdBBwN/EpEDk7l5qr6oKoOVtXB7du3T63lmSAcof3lbJj6jWWL7dIB9t3LRmrvtKNlg01EcTGsWFEmOABuugmaNYNLL019KlPHcZwqkElT1UKga2S/C7A4WkBV1wPnAoiIAD8EC6q6OFgvF5FxmOlrIrBMRDqp6hIR6QQsz+AzpIf1m2DOPJuytHEe7NbFoqAqExQVWbnShEOHDmXHdtoJbrjBBMe4cXDSSeltu+M4TgUyqXFMAnqJSHcRaQyMAV6KFhCRNsE5gAuAiaq6XkSai0jLoExz4Cjg66DcS8DZwfbZwIsZfIbqUVwCc+bDF99YGvLdu5mG0bVj6kIDysZwRDUOgIsugr32giuugM2bq91sx3GcRFQqOETklMhL/Pci8ryIDKrsOlUtBi4G3gC+AZ5V1Rki8gsR+UVQbA9ghojMwkxSlwXHOwAfisiXwOfAq6o6Pjh3E3CkiHyHRWyVC/HNGlauhckzYNFy2Lk9DOlnWkZ10nrEExyNGsE998D8+fDPf1a9fsdxnCSoNBxXRL5S1f4iciAWAXUrcJ2q7lsTDUwHNRqOW1gEcxbYOIxm+aZltG6RnroffxzOOQfmzIEePbY/v/vudvz119NzP8epD5SWwo8/wm671XZL6hzxwnGT6f6GGfJ+Atyvqi8CjROUb5ioWoTUpBk2HqNbZ9inb/qEBpRpHFEfR5RjjoEJE9xc5ThRxo+Hnj1h6tTabkm9IRlD+yIR+QdwBPB3EWlCZn0jdY/NBfDtjzbSu3VL2H1X0zbSzbJl0Lw5tIgjjI45Bu68E957z7Ydx4F586xj9+STMKhSK3vWowqrV8PixbBoka1Xr4amTS3AsuKyxx7Qpk1625CM4DgVGAncqqprg0im36a3GXWU0lJYsBTmLbEss7t3s/Tkmco2Gx3DEYuDD7ZvymuvueBwnJDVq239zDNwyy1pnT6guBgmToTnn4fp06F9e+jUyZaOHW3dtq39dOfPNxk2f74tixeb9eyAA2DYMBvLu+OO5etfuRImTYLPPoPPP7fhWosXQ2Fh8m18/XUYOTJtjwwkJzg6Yc7pQhE5FOgPPJHeZtRB1m+Eb+dZLqn2baHnLhZqm0kqExz5+TB8OLz6qmXP9XTpjlMmOBYtgg8/tA5WNSgogHfegf/9D156CVatst7+3nvDjBl2bu3a2Nc2bQq77gq77AJ9+pgguOUWE0Bgx/bf3+7x2Wcwd64dF4F+/WzMb5cusPPOtnTubOsddjBhsnmzLVu2lG3vs0+1HjcmyQiO/wGDRaQn8AgWDvsU0HC7tOs2wLTZ0CQP+vW0OS9qgmXL7JuViGOOgZdfhtmzKy/r1A2WLLHxOvUxRf6WLXDllbb06lXt6qIvz/AF2mnWKtq0bU+jwk3I00+nJDi2brWf0vTp8NVXtnzwAWzYAK1awXHHwcknw4gRpuxHH2vpUvvXrVljmscuu5hGUbE/t2WLaRUff2wp6F56yQTMvvvChRdaSrp99smudHTJCI5SVS0WkZOAO1T1bhH5ItMNy2rWbbT1oL6Z1zKiLF0Khx6auMzRR9v6tddccKTKpk3wyitwyinZMxvi/PkWLTdkiJladt65tluUXj76CB54AN59Fz791Ow6KVBQYKai114zk8y3325f5kVW05XOfN+oN0c+8l+e3etORh6bR9eu5ctt2ADTppkPfepU+PJLmDnThAfYbAZ9+sCYMTbO9vDDoXGcMKGmTaF7d1sqo2lTk2XVVIRqlGQEx1YROQ04CzguOFaDb8sspLDI5ryoSaFRVGQqdyJTFZge3K+f/ZKuvLJm2lZfePhhuPxy2LgRzj+/tltj/Pe/1o2eOtVsIf/5j72xElFQYLaPeEEU2cTXwbjeuXPh1FPte5sX+3elaiagefOsd/766yZvNm82K+2hh8IZZ5gmEHUUH/iH1RTn7MBnncfQ+o1neO6X7zL2lyPYc0/7KJcvt483KnQ6dYKBA803sNde0L8/9O4dX1A0NJIRHOcCvwBuVNUfRKQ78O/MNivLKSyCJjX8DVoeZFaJF4ob5ZhjbHrZDRuyS7/Ndt54w9bXXAOjRpnhuDImTLBQz4rd13Tx3/9aJNC//gU//SkceaSlmLnmmu21ogULLGPyQw/ZfPTTptlbtIYpLbWUaosXly1LlpRF/rRoUbYc+vIMurRuz/TT/87g+85jxogreHfUPRQUmEBYurS8Q3nDhrL77LYbnHeeKdmHHlreVFSO362Cvnvyi38fjXZozTOHPc3DB4zg9dfh/vtNiRs0CM4809aDBlXeP2vwqGqlCzZuY89gyUvmmmxa9tlnH00rk75W/erb9NZZ6T0nqYLqiy9WXnbCBCs7blymW1V/KChQbdpU9fDDVXNyVH/1q8qveecdVRHVX/4yM22aN8/+j3/7m+1v2KB62ml27JhjVFetUi0tVf3gA9VTTlHNzbW2/+Qntj7nnLQ2p7RUdf581eefV73uOtUzz1Q94QTVQw9VHTRItUcP1fbtVRs1siZWXFq23P7cx+yn73Koguot/FoV9Bfct+38Djuo7r236oknql56qeptt6n+97+qs2dbe5Jip51UL7zQts85R7VVK/t/q2pJSVo/onoHMFljvFMr1TiCSKrHsdn2BOgqImer6sQMybLsp7AovQP7kmFZMEVJMhrHAQeYpvHaa3DiiRltVr3hww/NS3nFFdC3L9x3H1xwgdkrYrF8OZx+ur3f5s/PTJuee87Wp5xi6xYtbCzCQQeZSW3QIPO2Tp1qgfpXXmnTCe+6K/zhDzZPywknJPwOFBXBJ5/YAtCkiS35+bZu1MgifyZNgsmTy76GjRpZRE/r1qbUdOpkppzWrU1R23lnOxZG/3TsWGbmKSoya+DGDUrnfjNY+ZOz+fJ30LTx39nyq2+47/1L+L8Xdidv5PAqpXQrRzjoIdQex4yBxx4zO9eJJ2aNK6vOEUuaRBdgCtA7sr87MKWy67JpSavGUVys+t4k1XmL01dnMjz8sHXBfvwxufInnaTauXMK3bIkKClRfeMN1fXr01dntnDVVap5edarX7PGus4HHBD78yspUR0xQrVJE9U99lAdODAzbdpvP+tux+Lzz+3e/fqpPvCA6saN5c8XFZka0K6d6tKl2w6XlqrOmqV6112qxx6r2rx5bO0guoio9u2retZZqnffrfrpp6qbN6fh+UKN6v77y46tW2c3a9tW9ds0aPXr19s9brnF9rdutc9k9Ojq190AII7GkYzg+CqZY9m8pFVwbNpsgmPpyurXVVqq+tJLqp98UnnZv/7V/l1btiRXdyhovvqqem2M8sADVmfr1vaiXbAgfXXXNgMHms0l5JFH7FmfeGL7sn//e9kL78ILTcikm/Cl+v/+X5UuLy1VXf7eDC1p3ER/HHCc/vY3pXrCCapdu5YJhF69zCL3wgsmK7dssfXSpdY/mT1bdfr0DPYTXnvNGvLBB+WPf/+96o47qvbubQ2qDj/8YPd49NGyYxddpNqs2fbC1tmO6giOR7HxG4cGy0PAPyu7LpuWtAqOVWtV3/lU9Y23rPdSVSZPVj3wQPsXJNNjveQSe2Eny6JFVvdNN1W5ieUoKFDt0sV6wKecYjb0Ro1UTz9ddcqU9Nyjtli6dPuXdEmJ6r77qnboYL3gkE8+sef+6U/t7fyXv9i1gc28KhQXq370kdnvH31U9fXXVRf++jZV0JLZ36mqfdXmzLFzd9+tetll5so44ADVoUPtK9Svn+ruu6t2727+BFC9jNtVQS9s9LD262f/un/8Q3Xu3Co3N33cfLM1cvXq7c+99559x/70p+rdY8oUu8cLL5Qde/99O/bUU9WruwFQHcHRBLgSeB4YB1wBNKnsumxa0io4Fi9Xvegy++h22cW+/LG++PFYskT1vPNM/2/fXnXwYLMXVGZSOuUU64GlwsCBqgcfnNo18bj3XnvmN9+0/R9+UL38ctUWLez4oYeqPvSQeU/rGv/6lz3D5Mnlj0+aZP+nK66w/dWrVXfdVbVbt7Ke8KOP2rUpvonXrlV99llzMO+4o25nHvqY/XQqA7VRI9WOHbd3KjdvrjpggPnyR45UPe44s06OGWN1Xnqp6j33qL7xeoluHna4lrZoYT35bOLss1V33jn++c6dq+/gf+st+8AmTiw7VlJidR9/fPXqzhaKi23JAFUWHPVhSavg+H6+6s5dVPfc016WYGrvRRepfvNN/OsKCqz337Kl2dJ/8xt7e9x9t9WxuBKfyUEHqR5ySGptve46i7Sprrq/ZYv90A48cHsBt3at2Y933bXsrdavn+qvf20/2mr0xGuMM880u3esEJuxY+0znD7d3syNGql+9lnZ+Tfe0JjmlgqsWmVFb7hBdfjwMkGwww6mtD39tCk+c+eqfv6/+aqgHx37//Taa62fce21Zj2bONG+Kim5rubNs0iiAw/M2AumSuyzj+qRRyY+f/TR1bvH00/bB/311+WPX3ml/Q5T6fTVNvffr9qzp2n+7dqVvUvA9lemwXxegZQFBzAd+CreEu+6bFzSKjgeekzLqblffKF67rnmKAV7K5x6qnUDhw0zAbPLLmU98+OPL+/0Gz/ejr//fuL77r671ZsKH35odT/7bGrXVSQUbu+8E79Maan9OG+9VfWII1QbNy4Tqlddlb1xjyUlZo467bTY51essLd7x45azska8vXXqqAlT/5H16wxc9Lnn5tJ6c47TSj06qXltIV+/ewj+eCDONbO//s/K/jdd+l7zieesDr//vf01VkdSkos/DnU5mJxzDHm4K8O991nz71kSfnjn3+u2/k+sp3dd1fdbTfrSfzyl/bZXXut6m9/a89y++1pv2U8wRF3IicR2bWSaKx5qURv1SZpncjpsCPgyy9gyWKLVwxZsQL+8Q8LlwSLUWzVysJiw+3jj4cjjihf39y5NvnSww8nHq3curVN4nTnncm3tbjYchydcELVZwbcssXa16uXpWtPNnHipk1W/sknbbTzOefYwLRqx1emmS+/hIED2Xj3P3muxTl8+qlFPIeJ6HbdFbqNf4C8Sy+i+Kij+erGV5j1bQ6zZsE338DCGev45Js2/FZu5Vb99XbV77yz5RoKl8GD7V+ZkGHD7HP/Io2ZfVRtAOErr1h4avPm1avv3Xdt2bChbFm/3tb77GNJNhPx/fc2cDLR9/688+DNN2Hhwqq388Yb4fe/t9H00d+rqn2nd9vN7lFd/vMfG3w5cWJm0tXMmWPtvesuuOSS7c/vt599/jNmpDW5abyJnGpdG6iJJW0ax/z55rC74ML01KdqXc68PNWrr45fZvNm61HceGPq9Y8ZYz3qqvb477jD7j1hQtWuLy1V/fOfrY6TT84q09WyZaqfnGQO2q65i7YFjImU1xByKNbzm/9HW7Om7FiOWQ2O/UmpbmnUXD8cernedpvqY4+pvvyyObsXLqxCo+bPr/r/ujKeecbqnjatevUUFpoWJmIfWJcuFho8dKj1ikXMNpeIF1+0tnz6afwy11xjv43qhJRfeaU5hGLxu9/ZP3LZsqrXr1pmygXz/WWC8HcYz08VRgFWYjJNFao6ANCJ8NBD9t44/cz01dmokfV6vvsufplw1FVV8iAccww8/bT1XlPNr7xlC9x0k+VzqCy5YjxE4I9/NI3riits5NfzzyfID5E5VK1D9uablkB44kR4o/QNZjfek9Ov3JmTT7aPaOtWy8A9b1645LJkyRh+09mS3PXpY50/68AK9OnCAbsu4oB0pAb73/9sHQ76Syc9e9r6++9hwICq1/PGG6a1vPwyHHts+XMffGDZ+j74wDTdeIQ5qvr2jV+mQwf7Z6xZk1z6l1isWrX9JBchp55qGskrr5h2U1Uefti+MGCpdLt1q3pd8Xj1VfvixZv+dvRoGxT64INw4IHpv39FYkmT+rakReMoKlLt1El132GqC5ZWXj4VfvIT1f7945//5BPrTbz6aup1L1tmPcBTT7UQ3VQIbe2V+V+S5eGHrS0HHmhO9RpgyRILmjrrLPv3hRpD376qf7lmk5bkNdbSK66s3k0OP1x1//3T0+D997dwqUywdq09/M03V6+e0aMtFKyoaPtzBQWq+fkWL5yIn/3MAioS8dRT1t6ZM6vaUgs3ixfuXlJiDuZk0svEY8sWiwzbc09r6513Vr2ueGzYYD7DX/86cbmLLjJfa2XaXgoQR+OokjFOROKI8O3KjRSR2SIyR0SuiXG+rYiME5GvRORzEdkzON5VRCaIyDciMkNELotcc72ILBKRacFSM/OCvPSSZWo74WTIT3OCw169zIapsf1NKaUbqchOO5lN9L//NYP9GWdY/ojK2LTJtI3DD09fvufzzzft59NPrd6VK9NTb4Rwkp2rrrJsIZ06WfK6V1+FQw6BRx6xDCEzZsAfDn6fnK1FyMgR1btp585lPc7qsGCB5f7IhLYB5lzZcUfTOKrKhg32Wxg9OnYW2yZNLOXNe+8lrufrry2LcyLC73v4/a8K0XQjFcnJsS/JtGlVr//hhy2L4x132Oc7e3bV64rH229bnpaf/CRxubFjLZPyv2sgB20saRJrAb4H7gKGAjOTKJ8bXLMbliTxS6BvhTK3AH8KtvsA7wTbnYBBwXZL4NvwWuB64DfJtlvTpXEMH2623Hc+VV2f5hGn4RiJeEbxcMR2lYzmAXPmWC8wHBm2//5m847Va1S16KEM2ExV1TSn/HzrpSUZKjxvnnWUb77ZAmWeeMKS7b31ljXx9tstcrNpU2t2Xp7qYYfZmL4pU+K4eC6/3NpR3fwZ115r8bXJ+JHWrrWxMLGGY99+uzV+9uzqtScRQ4da1FtVefxxa+NHH8Uvc8MNViZeeOjWrdaDvuqqxPcKItb06aer3t4+fWywZjwuucQiHqviAwy1jYMOMj/Mvvua9pluLrjAwqnj/VajDBliYXtpSjVEOsZxYIP/SoCzkii7P/BGZP9a4NoKZV4FDozsfw90iFHXi8CRWluCY/Zs+6iuusbSjRQm8Q9MhTff1IQO6Ouvt/PJfHEqY906U6d79LA6mzY1VX7MGLvPf/5j4xTat08cY19d3nqr7O2ewGE+ZYpZNXJzy8xM8Zbdd7f3wMsvm3ZfKX37qh51VPWf5Z57NGbIZyx+/3sr27ixvcBvv71MUAwbljkzVchpp9nQ8qpy5JF2faIXUxgG/vzzsc9/842df/zxxPdasaL65p9oZtxYhAM4qyKswzD1d9+1/bPOMid5OiktNeGUSPhFeeihygV7CsQTHHFNVSLyZjQkV0T2w+bluBA4Nt51EToDCyL7C4NjUb4ETgrqHwrsCnSp0I5uwN7AZ5HDFwfmrUdFJOaUYSIyVkQmi8jkFStWJNHcBDzwgDmxR/3UnL15aY4pCKfMjOcgX7bMTAxxJrhJiVat4NJLTaV++WW46CKLGf38c/jzn+G002zOyhUrbD/NbNlivvFTHzyCP3d7FCZM4NuDzueTj5WNwcSKqpa8dPhwc1a//LL5/ebNM9/60qX2UX3xBXz01mZ+OOEyVtzyGLO/KeWuu8xfW+kcRgsW2PRuRx1V/YfqEnxlkzFXffONlb/sMjNxXHGFpZXt1ctmJ8qUmSqkRw/7IIuKUr926VKzA/7sZ4lDPocMseCHeOaqGTNsveeeie+3ww42XW5VTVWqiU1VUJb9ONXQ54IC+NvfzIwbBo707m3fgfCLnA6mTbPvSWVmqpAxY+zL/+CD6WtDLGJJExM0TIts/wSYCewe7E+Kd13kmlOAhyP7ZwJ3VyjTCvgnMA34FzAJGBA53wLLzntS5FgHzAyWA9wIPFpZW6qlcWzebJk6Tz1VdcYc1c/SmDQwpLjYeqC//W3s86NGmfqZaTZvtqSIzz6r+r//pa3awkLVV15RPeOMMkvZTjtZNpQb8i154w38TkVssFzv3lamc2czTcX1o69ZY8maQpVj2LDkQ03D8MV0JIEM50qJ5kOKR//+FgwR8sMPZqo85hhLZZKpcM6Qf/7T2lqVzLOhKS0ZZ/WRR6rutVfsc9dfb0ESmzZVXk+nTqrnn59SM7dRMTNuLAoLTfO95prU6r7rrvLahqrqc8/ZsXTmbgvNfktTCMi58EIzwaZhVDxVGDn+GXA28HtgOdBZy172yfg4KjVVVSgv2JwfrYL9POAN4MoE13QDvq6sLdUSHOEPbcIE1akzVafNqnpdidhjDxMQsdh//8zYTjNAUZFZIv73P/vOjx5tchdsfcEFqm+/XTZiurSkVDeMuUAV9OXjH9STTrJMLo8/br/puCxdamadvDzz1fzzn2Zey80130U0MWEsRo+2l1I6bMGLF9sD3ntv4nKlpTaSvrKIo0zywQfW1tdfT/3awYPjp3mvyI032n1WrNj+3Cmn2CCYZBg40PK/V4VYmXHj3WPEiOTr3bLFvjsHH1z++zN9ut0v2eSJyfhV9tvP/BapECZ2vPvu1K6LQVUER0/gYeA+4NfA28AfAw3ginjXRa5vBMwFulPmHO9XoUwboHGw/XPgCS0TIk8Ad8Sot1Nk+wrg6craUi3BMXSovdRLS1U/mab6TYbSih53nDmLY7HbbmbozyLWr7eO9r//bWb7U04xpShMnRMu3bqZpvHKKwkEQVGRpWjJzbVU25Xxww/24mnWzBJAhaxebSGJIvbDfuqp2IKhuNgGsJ19dhWePAbFxeYcv/baxOVCAZOGH3SVCdtwzz2pXRf6+W67LbnyH31k5Z97bvtze+xhUwcmw4gRqb84Q2Jlxo3FOeeYCpxsJyKWtqFqAkUkuYy+GzZYRyeR/2b5cqvv+uuTa1eUffYxja+aHaN4giOusV5V5wAXhPsi8i5wBHC1qr4d77rI9cUicnGgNeQGJqUZIvKL4PwDwB7AEyJSgpnCwtwDB2CmrekiMi04dp2qvgbcLCIDAcU0lAsra0uVmTrVbP9hmo/CrZmba7xXL3jrLZuwuWLKgqVLa2US5JISC12dPduWWbPKthcvLiuXk2Pjkvr2heOOs3XfvjZeKanMFnl58OyzZi8+5RQbmTdoUOyyoV9i0yYLU9x//7JzbdvazH3nnmu+m5/9zNJNDBgAe+1VtqxZY7bvdPg3wOzwnTpV7uOYM8fW4UC82qBjR/M/pBqS++ST5tcYMya58lE/x8knlx0vLDQH1UknJVdPhw7mF6oKq1fburLBg3vvbbMCLl1q/8dEhL6NQw6Bww4rfy4/3wb/JROSO2WK+RGvugpGjDD/SEXGj7f+V7L+jShjx8KFF8Jnn1k6kjSTtJdXVb8AUvIgBS/61yoceyCy/QnQK8Z1H2JaR6w60zhsuxLuv9++/GedZdPFQvrHcIT06mVfykWLoGvXsuMbN8LmzVUbw1EFSkstFuCBB+Dbb+13HtKmjX2/jzzS1n362LpHj/JpgKpEy5Y22GK//WyMx/77l79J796Ws+joo20O0okTTQjEYsgQ+8GEU4ROnw4vvmgPF+XII6vZ6AhduiQvOHpt95WvOURMyqciOFRNcBx+uAVSJENeno1gnjCh/PFvv7UcapWN4Qjp0MGc46qp52BatcrW8UaOh+y9t62/+KJywfHQQzae66mnYp/v3Ts5wRHmzmvSxEatT5xoHZAor75qzx+vE5WI006zqYQffLB2BUeD5OqrrVfapg2s22DHMqlxgPXGooJj6VJb14DGMWsW/PznNv32/vvDxReXvbP79IH27dOaP217dt7Z8oH89a+mWUycaEIzSvfupmnES70QkptrAw7DBHpbtlid06fb0qGDPVC66NzZ6k3EnDkWnbfrronLZZoePRKnuKnI55+boPnd71K7z2GHwbXX2vzsO+1kx8KIqlQER2GhJfCrNDtkBZLVOML0K198YSl6EvHooxZ1GC8FT+/e9r2NZTmIMmWK/c5vvNE6pnffbaGDIcXFltpl1KiqJU1s2dI07n//G26/PfXPrhJccCSiZ88ys0KocdSE4Dj88LLjNSA4tm6FW26x6Nvmza2jftZZGRYS8ejTp2zka2mp9eJDO9mKFaZ+J9vrjdK0qcX2ppqvK1k6dzbtJlHP+LvvzJRR2xmCe/Swl1JlL7eQJ5+0nnGy5qWQ8OU6caJl5gUbMZ6bG9s0E4vo6PGqCo62MSP2y2jVyj6TykaQL1liZf72t/hl+vSxzk5Fy0FFJk+27+IZZ8Azz8B111kcefi++fhjWLu2amaqkLFjTUN6910TQGmk0m+NiBwrIhnIE1zHKMiw4OjSxWykoTkjpDrpRpJgyhSz7Pzud5aTbuZMOPvsWhIaFcnJsR/fEUeY+vPnP1dNaNQEXbqY32X9+vhl5sypXf9GSM+eZhZdsqTyslu3WpqY445L/cW9zz42piBqrpoxI5ohsnKqk3Zk1SrrCSVzr733rnwsxxtv2HrkyPhlQoGYyFy1bp11IgYPth/aP/5hpr0LLigzp776qh2rjjl1n33ghx/SLjQgCcEBjAG+E5GbRWSPtLegrlBYBI1ybckEOTmxTQhp1jhUzcz84IPm5xw61CwJ48aZf7oWfPD1g87B2NZ4fg7VsjkVapsePWydjJ/j7bdN0zvjjNTvE/o5ogMBv/668oF/UULBEf4OUmH16sr9GyEDB9rnsW5d/DLjx9sPJFFm4WQEx9Spth4cTHPRuTP83//B+++bcxFMcBx0kGlDVUUkM5l6SUJwqOoZ2Mjt74F/isgnwajslhlpUbZSWJQ5bSOkZ8/YgiMnB9q1q3K1331nfv4xY6zD3ru3WXzef9+Cj2bOhBNPrF7TGzyVjR5fscISBGaDxpGK4HjySTP1HH101e512GH2BVu2zPxM33+fvH8DqqdxVDZqPEroIP/qq9jni4vN/zZyZGJ1vFMn07ISCY7QMR41m553nvlTr7rKfpgzZlTPTJVhkjK2qup6Efkf0BS4HBgF/FZE7lLVSqb6qifUhODo1ct6NVHb87Jl5sStGHFRCd9/bxrEs8+WmW47dzb3ySGHmPm5V68sMUnVB0KNI95sddkQihuyyy72fapMcBQWwgsvwOmnWyRbVQj9HO+/b8+umprG0a6d/RZqSnB88YX19CsyaZKFcScyU4H9oCqLrJoyxQIkop1BEfNH9OtnZkGo24JDRI4DzgN6YGlBhqrqchFpBnwDNAzBUVAELStLgFRNevWyH+uCBWWRNymM4Zg3zwTFM8/YdxMsOur2283v1qOHC4qMEfpe4mkcoSaZDYIjL8++XxX9aRWZMsX8NlXVNsBCSVu2NHNVGNudisaRm2sv2Kr6OOKFbFekY0eL/Irn5xg/3gRYMj6H3r3ho4/in588ucxMFWWXXSxK5aKL7Me6++7Jtb0WSEbjOAW4XVUnRg+q6mYRqca0WXWIkhIoLsncGI6QaGRVKDiWLavUMb5uHfzpTxbRV1pqzu5bb7VAltqO/Gww5OfbCy6RxpGTkzGbc8r06FG5xhG+/KKDLFOlUSPrwU+YYAKkcePUhWc4liNVUtE4REzriBdZ9frrFoabTH29e9sc5Js3bz/T5Zo19rnHm2d97Fibr2bo0Kzu5SXjHP8T8Hm4IyJNg4y1qOo7GWpXdpHpUNyQUHBEe4IJNI5wXFafPjaH/dixMHeuhd3/+tcuNGqcRBM6zZljQqOqJp90k6zg6Nmz+hF9hx5q4dRvv20v1VSzPFdFcGgSmXErMnCg+RYqZg5escK0hGQ1r9697f6xxspUdIxXJCfH4uF/+ctkW10rJCM4/gtEh9yWBMcaDpkOxQ3ZeWcbbxB+4VTjCo4ZM8zveMYZFrH6+efmAO/ePbNNdBLQpUtijSMbzFQhPXta73fNmtjnVW0swQEHVP9eYWqOqVNT82+EVEVwbNhgDu1UBMfee1v4cThIMeTNN+3zqMy/EZIosiqWY7wOkozgaKSq20RwsJ0l3aYaItPpRkIqhuSuW2e9n0iP78cf4Te/sc7R9OkWAv7pp/E7ME4NEk/jCHuf2SQ4KousmjPHetrDhlX/XgMHloWVpuLfCImmHUmWcPBfsuG4UOYgr2iuGj/ezJDJvuxD30Q8wdG9e2oCLQtJRnCsEJHjwx0ROQFI/2TR2UwoOBqnYSKlyujVq0xwBLHr84s68pe/2Pe6e3e47TY45xz7Xo4dW7WMBE4G6NzZXrbRBF9gL7F16+qW4Aj9G+nQOBo1Kpu3vqoax5YtqU2QlGy6kSg9e9qAwaiDvLTUBv6NGJH8D61ZM3N0xxIcU6bUi15eMp/EL4DrRGS+iCwAriaTGWmzkcIiExo18Ybu1QudO5dJn5bwwPUmOM69tgPXX29WrJtvNrny0EPVGtrhZIJwLEc0dTCUdQSyYfBfSJjrK15k1ccfW462PdI05nf4cFv375/6tVUZy1EVwZGTY4P7ooJj6lTrDCRrpgqJFZK7apWN5K7jZipIIqpKVb8H9hORFoCo6obMNyvLKKiBMRzYb3jmN704vqiIU/efz7DcZTZX7x878u9fVJ6406lloqPHo86mbBrDEdK8ufnOEmkc+++fvs7SRReVqcypEhUcyX6GyWbGrcjee8Pjj5eNpRo/3qKbRoxIrZ7eva2eaO6yMEa+gWgciMhPgF8CV4jIH0Xkj5ltVpZRWJQx/8aqVRYRte++1iH9v5etV3rfFXN46AbTOE69tKMLjbpAqHFUdJDPmWMvj2yLXIgXWbV6tY32ToeZKqRJExt5WhVqSuMA88ds3GjhiWCCY599Us+k3Lu3OeijqVJCwVGVNOlZRjJJDh8ARgOXYHNknAI0nEBP1YyNGp8xwzTjyy4zH/gtt8BTk0xwHN3zO5ptWGb24cqyezrZQbx8VXPmmM272pOWpJl4guPTT22dDsd4OqiO4Ej1txMdQb5mDXzySepmKogdWTV5sn3m9eD3nMwAwGGq2l9EvlLVP4vIbcDzmW5Y1lBcDKWadsHx8cc2mjs/3+YcGjo0OKGdzLn23XfmUO3Qwb3fdYXWre1/F0vjyCYzVUjPnvDEE+Z4btq07PhHH9mI7W1fylom7O2nIjhSyYwbpV8/66yFfo7S0qqNnA8Fx6xZZWlXpkzJyKRKtUEyb6SCYL1ZRHYGtmLziDcMMjCG49VXLVN4+/YmQMr9PkXKkh3W0pSxThURiT0TYLZkxa1IGFn1ww/lj3/8sfW8k5r3twbIyzNfRaoaR6r+DbCe3B57WEju+PEWIFAVAdqliwnjUONYscJyAtUD/wYkJzheFpE2wC3AVGye7/9ksE3ZRZrHcDz+uM170a+fzbQXMwNFGJKbRLoRJ8uoOJZjzRrr/WajxhEKjmhk1datpgJni5kqJNVBgKmOGo+y994WTTV+vOWmqsrEWzk5Np4jFByhf6MeRFRBJYIjmMDpHVVdq6r/w3wbfVS14TjH05hu5JZbbPzFYYfZpFxx/W29eplzbuFC1zjqGhVHj2djRFVIrLEc06aZ6SqdjvF00LFjzQmOgQPtXosXVy/BY58+2wuOeuAYh0oEh6qWArdF9gtVNcFMJ/WQgiIzQeRVfbrP0lIb7X3VVTB6NLzyiuV7i0uvXuZbWb7cNY66RufO9sIJZ3LLZsGx4442ojsqOD7+2NZ1XeNYtapqpiooc5BD6mG4UXr3tlQPhYXmGN9997TP/V1bJGOqelNEThZJPVWjiIwUkdkiMkdErolxvq2IjBORr0TkcxHZs7JrRWQHEXlLRL4L1pkNUQgjqqqYqXLDBpsk6bbbbPbTp55Kwl8XtYe7xlG36Ny5TOhDmeAIB9xlEyLbR1Z99JFFgIWhxdlCTZqqBg609YAB1ZuquHdv60DMmVM2x3g9IRnBcSWW1LBQRNaLyAYRSTCxsiEiucC9wNFAX+A0Eelbodh1wDRV7Q+cBdyZxLXXYOazXsA7wX7mqMYYjh9/NI3/tdcs5flddyUZIOWCo+5ScSbAOXMsC2U0aimbiAoOVRMc2WamAhMcGzdaqvLKqEpm3Cht2lhvb+zYql0fEkZWffCBmS/riWMckps6tqWq5qhqY1VtFewnMxHuUGCOqs4NEiM+DZxQoUxf7OWPqs4CuolIh0quPQF4PNh+HDgxibZUnSqO4fjwQwvGmD/fUvlffHEKSkuHDjb9ZLjt1B0qjuXItuSGFenZ03o4xcX2ZV28OPvMVJDaWI6qZMatyLhx1U9tHiY7fPJJWzckwSEiB8dakqi7M7Agsr8wOBblS+Ck4D5DMed7l0qu7aCqSwCC9U5x2j1WRCaLyOQVK1Yk0dwYqELh1pQFx2OP2RStbdpYgEoyk4aVIwzJBdc46hoVR49n6xiOkB49LJJqwYL0JjZMN6kIjqpkxs0ELVuaqevDD8smiqonJOPx/W1kOx/TBqYAh1dyXaz+dcW8yDcBd4rINGA68AVQnOS1CVHVB4EHAQYPHpzStdtIMaKqtBSuvtpm3zviCJvGtcqDRHv1sggXFxx1i512ssFzixbZAM4VK7JfcICZqz76yDTdZKdbrUmqIjiyIXV5796mxfXuXUlETN0imSSHx0X3RaQrcHMSdS8Eukb2uwDl0oaq6nrg3KBeAX4IlmYJrl0mIp1UdYmIdAKWJ9GWqpHiGI4//cmExi9/CXfckfpEZ+XYbz9Ld9AqGaugkzXk5lo2yoULy3wH2Tj4LyQqOD7+2JKmVWXcQqapy4JjwoR6ZaaCJJMcVmAhkExS/UlALxHpLiKNgTHAS9ECItImOAdwATAxECaJrn0JODvYPht4sQrPkBwpaBz/+hf89a82lfA991RTaIAlsPr226yed9iJQzh6PJtDcUM6d7bpbKdNg6++yk4zFZgmB8kJjqpmxs0EoYO8HkVUQRIah4jcTZmZKAcYiPkmEqKqxSJyMfAGkAs8qqozROQXwfkHgD2AJ0SkBJgJnJ/o2qDqm4BnReR8YD6WdDEzJJlu5MMP4YILbGDfffel6V2fm5u9kThOYjp3hq+/zu5Q3JDcXMva+9//mq01WwVH48Zm961rGkeoaRx0UO22I80ko5NOjmwXA/9R1Y+SqVxVXwNeq3Dsgcj2J0BMPT7WtcHxVcDwZO5fbQqL7IfVKDdukblzYdQoSx3y3HP2/XYaOF262Kxx331nztFsyfkUj549bYSziJmqspVkx3JUNTNuJjjwQItW69q18rJ1iGQEx3NAgaqWgI2xEJFmqppEQHUdp2M7aB3fobV2rWW4LSmx0eDZ0MFxsoDOnW3MwdSp2W2mCgn9HHvtld0jm5MVHFXNjJsp6pnQgOR8HO8AUZtJU+DtzDQny2jZHHaKLQ22boVTTzVrxPPPZ7f/06lhwrEcX31VN74YoeDIxvEbUVLROLLBv1GPSUbjyFfVbbPEq+pGEWmWwTZlPapw6aXw1lvw6KNl6fYdByifrqMuaBxhG7PVvxGSiuBw9T+jJKNxbBKRbSkdRWQfYEvmmpT9vPEGPPCAJS0899zabo2TdXSOjHOtC4Jj+HC46SY4+eTabkliOnSwsTEFBYnLueDIOMloHJcD/xWRcBxFJ2wq2QbLzJm2vvba2m2Hk6XUNcHRpImNXM12omM5dk0we/WqVdk5iLEekcwAwEki0gfojY3onqWqWzPesixm+XKLnspmP6JTi+Tnm409WydwqqskKzhc48g4yeSq+hXQXFW/VtXpQAsRqWb2r7rNsmU2HsnH5jlx6dzZ0sWEySqd6pPM6PHqZsZ1kiIZH8fPVXVtuKOqa4CfZ6xFdYDly8sGsjpOTIYOtRh+J30kIzjSkRnXqZRkfBw5IiKqqrBtrowGPczNJ+ZzKuWhh2q7BfWPZARHtmTGrecko3G8gaX4GC4ihwP/AcZntlnZTWiqchynBsnPt6SfyQgO1zgySjIax9XAWOAizDn+JtBgu1OqbqpynFqjsrEcLjhqhGRmACxV1QdU9aeqejIwA7g7803LTjZssLnn3VTlOLVAZYIjmzLj1mOSSqsuIgNF5O8i8iNwAzAro63KYsLvrGscjlMLuMaRFcQ1VYnI7tg8GKcBq4BnAFHVw2qobVnJ8mDaKBccjlMLdOgA774b/7wLjhohkY9jFvABcJyqzgEQkStqpFVZTCg43FTlOLVAhw6wZg0UFcWew2DVKhs74/MbZJREguNkTOOYICLjgaeJPRd4g8JNVXWPrVu3snDhQgoqy3HklCM/P58uXbqQV+3pLNNI2GNbvrx8MskQH/xXI8QVHKo6DhgnIs2BE4ErgA4icj8wTlXfrJkmZhehxtG+fe22w0mehQsX0rJlS7p164b4cP+kUFVWrVrFwoUL6d69e203p4zoWA4XHLVGMlFVm1T1SVU9FugCTAOuyXTDspXly+17mU2dMCcxBQUF7Ljjji40UkBE2HHHHbNPS6tsEKALjhohqaiqEFVdrar/UNXDM9WgbMcH/9VNXGikTlZ+ZpUJjlWrPBS3BkhJcDg++M9xahXXOLKCjAoOERkpIrNFZI6IbGfeEpHWIvKyiHwpIjNE5NzgeG8RmRZZ1ovI5cG560VkUeTcMZl8hoq44HCcWqR5c1tiCQ7PjFtjJJNypEoEyRDvBY4EFgKTROQlVZ0ZKfYrYKaqHici7YHZIvKkqs4GBkbqWQSMi1x3u6remqm2J2LZMpswzXGcWiLeIMAwM66bqjJOxgQHMBSYo6pzAUTkaeAEICo4FGgpZkxtAawGiivUMxz4XlXnZbCtSVFUZCHkrnHUXS4ffznTlk5La50DOw7kjpF3JCxz4oknsmDBAgoKCrjssssYO3Ys48eP57rrrqOkpIR27drxzjvvsHHjRi655BImT56MiPCnP/2Jk7N9SteaZpdd4P33Ye5c2G23suM++K/GyKTg6AwsiOwvBPatUOYe4CVgMdASGK2qpRXKjMEy8ka5WETOAiYDvw7mCCmHiIzFkjOyyy67VPUZyrFypa1dcDip8uijj7LDDjuwZcsWhgwZwgknnMDPf/5zJk6cSPfu3VkdvPRuuOEGWrduzfTp0wFYs2a7r7Zz661w1FE238lbb0G/fnbcBUeNkUnBESskQyvsj8DCew8HegBvicgHqroeQEQaA8cD0dm978fyZWmwvg04b7sbqT4IPAgwePDgivetEqF27KPG6y6VaQaZ4q677mLcOLO2LliwgAcffJCDDz542xiJHYKX3dtvv83TTz+97bq2bdvWfGOznX32MY3jqKPgkENg/HgYPNgFRw2SSef4QqBrZL8LpllEORd4Xo05wA9An8j5o4GpqrrNoKmqy1S1JNBMHsJMYjWC56lyqsJ7773H22+/zSeffMKXX37J3nvvzYABA2KGu6pqdobBZht77gkffAAtW8Lhh8PEiZ4ZtwbJpOCYBPQSke6B5jAGM0tFmY/5MBCRDkBvYG7k/GlUMFOJSKfI7ijg6zS3Oy4uOJyqsG7dOtq2bUuzZs2YNWsWn376KYWFhbz//vv88MMPANtMVUcddRT33HPPtmvdVJWAHj3gww9tfvcRI+DZZ+24axwZJ2OCQ1WLgYuxGQS/AZ5V1Rki8gsR+UVQ7AZgmIhMB94BrlbVlQAi0gyLyHq+QtU3i8h0EfkKOAxLhVIjuKnKqQojR46kuLiY/v3784c//IH99tuP9u3b8+CDD3LSSScxYMAARo8eDcDvf/971qxZw5577smAAQOYMGFCLbc+y+nc2bSNPfaA54NXhQuOjCPBVOL1msGDB+vkyZOrXc9VV8Fdd8GWLeDWhLrDN998wx577FHbzaiT1JnPbt06OPZY+P57WFzRIu5UFRGZoqqDKx7PpHO83hEO/nOh4ThZRuvWMGGCCRAn43jKkRRYtszNVI6TtTRq5I7xGsIFRwp4uhHHcRwXHCnhgsNxHMcFR9KomuBwU5XjOA0dFxxJsm6d5apyjcNxnIaOC44k8cF/juM4hguOJPHBf051GDZsWG03wXHSho/jSBLXOOoHl18O06alt86BA+GOOxKX+fjjj9N7U8epRVzjSBIXHE51aNGiBWAJD4899thtxy+++GIee+yxuNf95S9/YciQIey5556MHTuWMNPDnDlzOOKIIxgwYACDBg3i+++/B+Dmm29mr732YsCAAVxzzXaTbjpOWnCNI0lCU1X79rXbDqd6VKYZZBsXX3wxf/zjHwE488wzeeWVVzjuuOM4/fTTueaaaxg1ahQFBQWUlpby+uuv88ILL/DZZ5/RrFmzbYkTHSfduMaRJMuX26DURi5qnRpkwoQJ7Lvvvuy11168++67zJgxgw0bNrBo0SJGjRoFQH5+Ps2aNePtt9/m3HPPpVmzZkDZHB+Ok278NZgkPvjPSQeNGjWitLRsksuCgoK4ZQsKCvjlL3/J5MmT6dq1K9dffz0FBQXES0zqc3k4NYVrHEnieaqcdLDrrrsyc+ZMCgsLWbduHe+8807csqFQadeuHRs3buS5554DoFWrVnTp0oUXXngBgMLCQjZv3sxRRx3Fo48+yubNmwHcVOVkDBccSeIah5MOunbtyqmnnkr//v05/fTT2XvvveOWbdOmDT//+c/Za6+9OPHEExkyZMi2c//617+466676N+/P8OGDWPp0qWMHDmS448/nsGDBzNw4EBuvfXWmngkpwHi83EkSdu2cMYZcPfdaWqUU2PUmTklshD/7Bo28ebjcI0jCQoLYe1aN1U5juOAO8eTYsUKW7upyskUo0aN2jb/eMjf//53RowYUUstcpz4uOBIAh/852SacePG1XYTHCdp3FSVBOHgPxccjuM4LjiSItQ43MfhOI6TYcEhIiNFZLaIzBGR7RLniEhrEXlZRL4UkRkicm7k3I8iMl1EponI5MjxHUTkLRH5Lli3zeQzgJuqHMdxomRMcIhILnAvcDTQFzhNRPpWKPYrYKaqDgAOBW4TkcaR84ep6sAK4WDXAO+oai/gnWA/oyxfDvn5EOSpcxzHadBk0jk+FJijqnMBRORp4ARgZqSMAi3F8iS0AFYDxZXUewImZAAeB94Drk5bq2MQjhr3bA5OOrj++utp0aIF69ev5+CDD+aII46o7SY5TkpkUnB0BhZE9hcC+1Yocw/wErAYaAmMVtUwkY8Cb4qIAv9Q1QeD4x1UdQmAqi4RkZgGJBEZC4wF2GWXXar1ID5qvB4xZz5s3JzeOls0g56pf8f+8pe/pLcdjlNDZNLHEat/XnGY+ghgGrAzMBC4R0RaBecOUNVBmKnrVyJycCo3V9UHVXWwqg5uX81c6C44nOpy44030rt3b4444ghmz54NwDnnnLMt/9SkSZMYNmwYAwYMYOjQoWzYsIGSkhJ++9vfMmTIEPr3788//vGPuPVv3LiR4cOHM2jQIPbaay9efPHFbeeeeOIJ+vfvz4ABAzjzzDMBWLZsGaNGjWLAgAEMGDDAJ5pyUiKTGsdCoGtkvwumWUQ5F7hJLe/JHBH5AegDfK6qiwFUdbmIjMNMXxOBZSLSKdA2OgHLM/gMgJmqEqQUcuoSVdAMqsuUKVN4+umn+eKLLyguLmbQoEHss88+284XFRUxevRonnnmGYYMGcL69etp2rQpjzzyCK1bt2bSpEkUFhZywAEHcNRRR9G9e/ft7pGfn8+4ceNo1aoVK1euZL/99uP4449n5syZ3HjjjXz00Ue0a9duW+LDSy+9lEMOOYRx48ZRUlLCxo0ba+zzcOo+mRQck4BeItIdWASMAX5Wocx8YDjwgYh0AHoDc0WkOZCjqhuC7aOAUK9/CTgbuClYv0gGUXWNw6keH3zwAaNGjdo2T8bxxx9f7vzs2bPp1KnTtiSGrVqZ0v3mm2/y1VdfbdNK1q1bx3fffRdTcKgq1113HRMnTiQnJ4dFixaxbNky3n33XX7605/Srl07oGyOjnfffZcnnngCgNzcXFq3bp2BJ3fqKxkTHKpaLCIXA28AucCjqjpDRH4RnH8AuAF4TESmY6atq1V1pYjsBowL5hZoBDylquODqm8CnhWR8zHBc0qmngEsR1VxsQsOp3okmicj3jwaqsrdd9+dVNqRJ598khUrVjBlyhTy8vLo1q3btrk7fI4OJ91kdByHqr6mqrurag9VvTE49kAgNFDVxap6lKrupap7quq/g+NzVXVAsPQLrw3OrVLV4araK1hndNKBcNS4D/5zqsrBBx/MuHHj2LJlCxs2bODll18ud75Pnz4sXryYSZMmAbBhwwaKi4sZMWIE999/P1u3bgXg22+/ZdOmTTHvsW7dOnbaaSfy8vKYMGEC8+bNA2D48OE8++yzrFq1Ciibo2P48OHcf//9AJSUlLB+/fr0P7hTb/FcVZXgg/+c6jJo0CBGjx7NwIED2XXXXTnooIPKnW/cuDHPPPMMl1xyCVu2bKFp06a8/fbbXHDBBfz4448MGjQIVaV9+/bbJm+qyOmnn85xxx23bS6OPn36ANCvXz9+97vfccghh5Cbm8vee+/NY489xp133snYsWN55JFHyM3N5f7772f//ffP9Efh1BN8Po5KeO45OOUU+PJL6N8/zQ1zagSfU6Lq+GfXsPH5OKqIm6ocx3HK46aqSli+3EaM77hjbbfEcWD69OnbxmKENGnShM8++6yWWuQ0RFxwVMLy5SY0Gvkn5WQBe+21F9OmTavtZjgNHDdVVUKYp8pxHMcxXHBUgg/+cxzHKY8LjkpwweE4jlMeFxyV4KYqJx208MlcnHqEC44EFBTA+vWucTiO40TxWKEErFhhaxcc9YjLL4d0RyUNHAh33JFUUVXlqquu4vXXX0dE+P3vf8/o0aNZsmQJo0ePZv369RQXF3P//fczbNgwzj//fCZPnoyIcN5553HFFVekt+2OUwVccCTAB/856eb5559n2rRpfPnll6xcuZIhQ4Zw8MEH89RTTzFixAh+97vfUVJSwubNm5k2bRqLFi3i66+/BmDt2rW123jHCXDBkQDPU1UPSVIzyBQffvghp512Grm5uXTo0IFDDjmESZMmMWTIEM477zy2bt3KiSeeyMCBA9ltt92YO3cul1xyCT/5yU846qijarXtjhPiPo4EuOBw0k283HAHH3wwEydOpHPnzpx55pk88cQTtG3bli+//JJDDz2Ue++9lwsuuKCGW+s4sXHBkQA3VTnp5uCDD+aZZ56hpKSEFStWMHHiRIYOHcq8efPYaaed+PnPf87555/P1KlTWblyJaWlpZx88snccMMNTJ06tbab7ziAm6oSsnw5NGsGzZvXdkuc+sKoUaP45JNPGDBgACLCzTffTMeOHXn88ce55ZZbyMvLo0WLFjzxxBMsWrSIc889l9LSUgD+9re/1XLrHcfwtOoJePhh+OQTeOSRDDTKqTE8NXjV8c+uYeNp1avABRe40HAcx6mICw7HcRwnJVxwOA2ChmCSTTf+mTnxyKjgEJGRIjJbROaIyDUxzrcWkZdF5EsRmSEi5wbHu4rIBBH5Jjh+WeSa60VkkYhMC5ZjMvkMTt0nPz+fVatW+YswBVSVVatWkZ+fX9tNcbKQjEVViUgucC9wJLAQmCQiL6nqzEixXwEzVfU4EWkPzBaRJ4Fi4NeqOlVEWgJTROStyLW3q+qtmWq7U7/o0qULCxcuZEWYQ8ZJivz8fLp06VLbzXCykEyG4w4F5qjqXAAReRo4AYgKDgVaiogALYDVQLGqLgGWAKjqBhH5Buhc4VrHSYq8vDy6d+9e281wnHpDJk1VnYEFkf2FwbEo9wB7AIuB6cBlqloaLSAi3YC9geikyheLyFci8qiItI11cxEZKyKTRWSy9zQdx3HSRyYFh8Q4VtHIPAKYBuwMDATuEZFW2yoQaQH8D7hcVdcHh+8HegTllwC3xbq5qj6oqoNVdXD79u2r/hSO4zhOOTIpOBYCXSP7XTDNIsq5wPNqzAF+APoAiEgeJjSeVNXnwwtUdZmqlgSayUOYScxxHMepITLp45gE9BKR7sAiYAzwswpl5gPDgQ9EpAPQG5gb+DweAb5R1f+LXiAinQIfCMAo4OvKGjJlypSVIjKvkmLtgJWV1VUP8eduWPhzNzyq8+y7xjqY0ZQjQajsHUAu8Kiq3igivwBQ1QdEZGfgMaATZtq6SVX/LSIHAh9gfo/Q53Gdqr4mIv/CzFQK/AhcGBEk1Wnr5FhD6+s7/twNC3/uhkcmnj2jSQ5V9TXgtQrHHohsLwa2m2RAVT8kto8EVT0zzc10HMdxUsBHjjuO4zgp4YKjjAdruwG1hD93w8Kfu+GR9mdvEGnVHcdxnPThGofjOI6TEi44HMdxnJRo8IKjsgy+9YkgRctyEfk6cmwHEXlLRL4L1jFTuNRl4mVbru/PLiL5IvJ5JPv0n4Pj9fq5wZKsisgXIvJKsF/vnxlARH4UkelB5vDJwbG0P3uDFhyRDL5HA32B00Skb+22KqM8BoyscOwa4B1V7QW8E+zXN8Jsy3sA+wG/Cv7P9f3ZC4HDVXUANvZppIjsR/1/boDLgG8i+w3hmUMOU9WBkbEbaX/2Bi04iGTwVdUiIMzgWy9R1YlYBuIoJwCPB9uPAyfWZJtqAlVdoqpTg+0N2AulM/X82YNUPhuD3bxgUer5c4tIF+AnwMORw/X6mSsh7c/e0AVHMhl86zsdwpH3wXqnWm5PRqmQbbneP3tgspkGLAfeUtWG8Nx3AFdRlnUC6v8zhyjwpohMEZGxwbG0P3tGR47XAZLJ4OvUEypmW7aUaPUbVS0BBopIG2CciOxZy03KKCJyLLBcVaeIyKG13Jza4ABVXSwiOwFvicisTNykoWscyWTwre8sE5FOYAkksZ5pvSNOtuUG8ewAqroWeA/zcdXn5z4AOF5EfsRMz4eLyL+p38+8jSCNE6q6HBiHmePT/uwNXXBsy+ArIo2xDL4v1XKbapqXgLOD7bOBF2uxLRkhQbblev3sItI+0DQQkabAEcAs6vFzq+q1qtpFVbthv+d3VfUM6vEzh4hI82CqbUSkOZYH8Gsy8OwNfuR4rAy+tduizCEi/wEOxdIsLwP+BLwAPAvsgqW5P0VVKzrQ6zTxsi1jfo56++wi0h9zhuZincRnVfUvIrIj9fi5QwJT1W9U9diG8MwishumZYC5IZ4KMpKn/dkbvOBwHMdxUqOhm6ocx3GcFHHB4TiO46SECw7HcRwnJVxwOI7jOCnhgsNxHMdJCRccjpMGRKQkyEgaLmlLoici3aIZjR2ntmnoKUccJ11sUdWBtd0Ix6kJXONwnAwSzI/w92BejM9FpGdwfFcReUdEvgrWuwTHO4jIuGAOjS9FZFhQVa6IPBTMq/FmMBLccWoFFxyOkx6aVjBVjY6cW6+qQ4F7sCwFBNtPqGp/4EngruD4XcD7wRwag4AZwfFewL2q2g9YC5yc0adxnAT4yHHHSQMislFVW8Q4/iM2mdLcINHiUlXdUURWAp1UdWtwfImqthORFUAXVS2M1NENS4neK9i/GshT1b/WwKM5zna4xuE4mUfjbMcrE4vCyHYJ7p90ahEXHI6TeUZH1p8E2x9j2VsBTgc+DLbfAS6CbZMwtaqpRjpOsnivxXHSQ9Ngpr2Q8aoahuQ2EZHPsI7aacGxS4FHReS3wArg3OD4ZcCDInI+pllcBCzJdOMdJxXcx+E4GSTwcQxW1ZW13RbHSRduqnIcx3FSwjUOx3EcJyVc43Acx3FSwgWH4ziOkxIuOBzHcZyUcMHhOI7jpIQLDsdxHCcl/j/YiQWOvlacmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training accuracy and loss plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(epochs, acc, color='green', label='Training accuracy')\n",
    "plt.plot(epochs, iu_acc, color='blue', label='Training iu_accuracy')\n",
    "plt.plot(epochs, dice_acc, color='pink', label='Training dice_accuracy')\n",
    "plt.plot(epochs, loss, color='red', label='loss')\n",
    "plt.title('Training acc and loss')\n",
    "plt.ylabel('Accuracy & loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['acc', 'iu_acc', 'dice_acc','loss'], loc='best')\n",
    "\n",
    "plt.savefig(\"D:/Anil/saved_model/UNet/Training_acc_loss_pretrained_UNet_50epochs_10000_it.png\", bbox_inches=\"tight\", pad_inches=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAA+x0lEQVR4nO3deXgV5dn48e+dk419DWvYwRUBJVq34r5WRaqt+rN1aSu11ba2b219tYvV+tZaW+tWK620orbuuNcF1KIVFbCgqCCLIAGEsCYhC8k59++PeyY5CSfJyclyAtyf65pr5sz6zPbczzMzZ0ZUFeecc665MtKdAOecc7snDyDOOedS4gHEOedcSjyAOOecS4kHEOeccynxAOKccy4lHkDcXktESkVkZLrTkW4i8rqIfKuBYdeLyIPtnSa3e/AA4jqkIHMPm5iIlMf9vjCF+e2SSapqV1Vd2Xqpdm7vkpnuBDiXiKp2DbtFZBXwLVWdlb4UOefq8xqI262ISIaIXCMiK0Rks4g8KiK9g2G5IvJg0H+biMwTkf4ichPwReCuoAZzVzC+isjooPvvInK3iDwvIiUi8o6IjIpb7skislREtovIn0Tk341c9jlMROYGaVgvIneJSHbc8ANF5BUR2SIiG0Tk2qB/RESuDdatREQWiMiQBpbxmIh8HqRnjogcGDesqXU5SUSWBNPeBUgztv9ZIvJhsG6vi8j+ccN+KiJrg2UuFZET4rbHfBEpDtb3D8kuz3VsHkDc7ub7wNnAMcAgYCtwdzDsYqAHMAToA1wOlKvqdcAbwJXBZasrG5j3BcCvgF7AcuAmABHpCzwO/G8w36XAkY2kMQr8EOgLHAGcAHw3mFc3YBbwYpD+0cDsYLofBWk4HegOfAMoa2AZ/wLGAP2A94CHmrEuTwA/C9K3AjiqkXWpISL7AP8ErgLygBeAZ0UkW0T2Ba4EDlXVbsApwKpg0tuB21W1OzAKeDSZ5bmOzwOI2918G7hOVQtVtRK4HjhXRDKBKiyDH62qUVVdoKrFzZj3k6r6rqpWYxnyhKD/6cCHqvpkMOwO4POGZhIs921VrVbVVcC9WMADOAP4XFV/r6oVqlqiqu8Ew74F/ExVl6pZpKqbG1jG9GDacBuMF5EeSa7LR6r6uKpWAX9sbF3qOQ94XlVfCaa9FeiEBdMokAMcICJZqrpKVVcE01UBo0Wkr6qWqurbSS7PdXAeQNzuZhgwM7iEsg34GMu8+gMPAC8BD4vIOhG5RUSymjHv+Iy0DAjvwwwC1oQD1N5AWtjQTERkHxF5LrjEVAz8H1baB6sdrWhg0saGxc8/IiI3B5e6iqkt6feNG60567KG5AwCVsdNGwumHayqy7GayfXARhF5WEQGBaN+E9gHWBJcVjwjyeW5Ds4DiNvdrAFOU9WecU2uqq5V1SpV/ZWqHoCVis8ALgqma8lrp9cD+eEPEZH43wncAywBxgSXba6l9j7DGuwyTiKNDYv3/4DJwInYJbvhYdKSmHY9FqhsAluXhPdZEliHBfD6064FUNV/qOrRwTgK/Dbov0xVL8Aut/0WeFxEuiS5TNeBeQBxu5s/AzeJyDAAEckTkclB93EicpCIRIBi7NJJNJhuA5Dqfz6eBw4SkbODS2VXAAMaGb9bsPxSEdkP+E7csOeAASJylYjkiEg3EflCMOyvwI0iMkbMOBHp08D8K4HNQGeshtOcdTlQRL4crMv3m1iXeI8CXxKRE4Ka3f8E6XhLRPYVkeNFJAeoAMoJtr2IfE1E8oIay7ZgXtFdZ+92Nx5A3O7mduAZ4GURKQHeBsIMeAB2s7sYu7T1b+DBuOnOFZGtInJHcxaoqpuArwC3YJn2AcB8LPNM5MdYLaEE+AvwSNy8SoCTgDOxy0zLgOOCwX/AMumXg3W4D7vHUN8M7FLSWuAjbBs0d11uDtZlDPCfJKddCnwNuBPYFKzDmaq6E7v/cXPQ/3OstnFtMOmpwIciUorth/NVtSLZNLuOS/yDUs41j4hkYPdALlTV19KdHufSxWsgziVBRE4RkZ7BJZrwnoY/TeT2ah5AnEvOEdgTUuGlm7NVtTy9SXIuvfwSlnPOuZR4DcQ551xK9qqXKfbt21eHDx+e7mQ459xuZcGCBZtUNa9+/70qgAwfPpz58+enOxnOObdbEZHVifr7JSznnHMp8QDinHMuJR5AnHPOpcQDiHPOuZR4AHHOOZeStAYQEZkuIhtFZHEDw0VE7hCR5SLyvogcEjfs1OCzmctF5Jr2S7VzzjlIfw3k79ibOhtyGva20DHAVOw7CwSv6747GH4AcIGIHNCmKXXOOVdHWv8HoqpzRGR4I6NMBmYEX017O3iZ3UDsAzrLVXUlgIg8HIz7UVuk84VlLzBv7TwyMzKJZESISKSmnZmRSWZGJlmRLLIysmq6MzNs00ZjUWIa26WJqvWPH67BN48EQURq2qpKVKNUx6qpjlUTjVl3VKMIQoZk1DQitb8jErF2RqROv0iGpTt+PTIko8F0xi8vXH5Uo7vMK9w+GZKxyzqE7UTC1+mE6x//ep2G1q2h+cSnOT7tIlKzr+IbgMrqSiqqK6iMVlJZXUlltJKd0Z11tld8t6qi2LLC7nDZiRoRISsji+xINlmRoB0cK/XnE3aH+7p+kyEZddIfbv/wGAmPp7A70TEVv13rr1uGZOyyLmG6GhO/HeL3Y/3jPVw/oGZ/NnSsxLcTnTfh8Z9ov4oIVdEqqmJVNe34bdicJjzH6qc3/vyOT5eiCY+biEQa3H7hfq1/PlXHqimvLqe8qpyK6oqa7qhGa/Oe4FhqqAnneXj+4fTr0q/R/dhcHf2PhIOp+7nNwqBfov5fIAERmYrVXhg6dGhKiXj+k+f50/w/pTStc851BC9e+CKnjD6lVefZ0QNIoiKrNtJ/156q04BpAAUFBSm9OfLuL93NnaffuUupNr5WUBW1Ek5Y4glLvfE1gbAUU79mEP4Oaxv1S3JAbWkirtYTlsQbKvnWL/nFp79+bSKmsTrpjG8SlYzCGkv9mkl1rLqm1NrQuiQSlozDkp0gjZbsG6rN1C/xhWmvX4sLG1UlNzOXnMwcciI55GTmkJuZS1ZGVsISbzQWbbDk3ND2i2ms5rjYGd1JVczaYWk4nD6+O1GpMpIRqUlL/fUIlx9fo4yvUYTbEqipUdQ/LsLuRLW+hmqQqlpnn9WvbcZvk/jaafxxUb8ml6idqEYdkQiKJtweMY3VXBWIb8dvj/rboH6/+P7hcRifXiDh9hYk4XET1ph22YbBPBPlK5kZmXTK7ESnrE7kZubWdEckQlSjNXlNTT4Uq0q4Papj1YzuPbrRczAVHT2AFFL3e8352HeZsxvo32YyJIOMSAZZZLXlYpxzzdXwlaGEwiDX0KXQ3UWECNmR7LSmoaNvwWeAi4KnsQ4HtqvqemAeMEZERohINnB+MO7eQxV2lMPOKut2zrl2ltYaiIj8EzgW6CsihcAvwYr4qvpn4AXgdGA5UAZcGgyrFpErgZew8sd0Vf2w3VcgXWIx+GQ1bNhsvyMR6JQTNLnQORd6dIXcnPSm07mORNUKXNlZ0MAlUNc86X4K64ImhitwRQPDXsACTHpFo3Ywhk1zqFowiMagOmoHdmYT9fFoDD5eAZu3Q35/yMmG8goor4SSMijaWjtul07Quwf06QHdu7beSbOzCioqbX4ZGRDJsHbYvTufnBWVsGkblOywbdsp1wJz51zIyqxdt1gs2A47oXKndffqDl07t256VC0t20qgeIf1y4xAZqa1s4LuME3RWN12hlhBIifb2rnZtp86ElXYtBXWb7K05WTZuZCdbd052bb9W3pcfbYeVq2z7dWzK/ToBj272XmyOx+zadTR74F0LFXVdjKX7LDMumSHZRyh+Iw0I8Nu9SvU3N8PrzTFYhZ4ovUejcyMwIjBMDAv8QFdXQ2Ll8P2UhgzFAYleCQvFrNgsmW7NYUbYM3nNu/ePexErJ/hZ2TUDYJCbXc0BmXldrlsR4V1V1U3va3CeWYEjQTLysqErCzIzrQTOTv8HTQ5Wc3P4FRte1ZV2zIjkdr1Smba0nLYvNUCx47gK7XZWTa/+MuDkQzLzKqjdfd7SAT2GQYD+ja93Opq249hEK7ZVhm2D7eXWNDYVmrrBhbMMsSWX1296/FTXziv+rKzLNMcMRi6dWk6rfWFl0+3l1qzs4o6z7CEndlZkNcT+vS0fZJoPpu2wur1Nr/cHNvG20tt/eL16g4Hjko8n2Rs3GLBo08PO+62l9j+Bjs3enSDAX0src0JJqp2vu0orz1PVGHowNS2bWPLKdlhBcct222ZibZ5JMMKMd26QPcu1s5uu/u2e9UnbQsKCjSl74Gs+RzWFVnpNNQpF7p1thNRFWJaW+oLmxpS97mxSAZkRCAzo25mt2GzZRpdO8HooXZQh3ZWwQfL7ADdbwSa15tPPoGRIy3/bVB1NWwtrj3wksn8E4lkQOdOtr5dcm39ldp1jS/5asy2R7hdwppWdZDJh02YMdaXGbGDPizxxwe1cFtWRaGqyuZTHU18H0jE5hWJBEEsQZAMaxBgtbS+PS0T6Zxr86yotJO1vNJqehU7rdSfk13bhKX6pats/w3Kg1FDEgcwVdvPKwub3hedcqyE3LO7tetnBOE2rY7W7qOaAkywnqq2fuF6VlRa95btdkwN7gfDBzde81WF0jJbt+0lQQYfLDMnC3Jy6j0XGWzfsgpbRoZA757Qr5cVYjIyLPNevc6O5865MGwg5PWuW8OrrIKdO215n661/XPQ6NoaV7KKd8CiJdC1C4zfp3a/VFQG61QKW7fb8jrlwOD+FkwSBatYDLaWwJZtUFxq6xiLO/Zyc2oLM/16w4h8Oz4SqdwJ64tgw5bammJuWFMMuuMLg+HxEgaGcFvHtaiOWqAJC0Jhmrp3gSEDUq4hi8gCVS3Ypb8HkCSs3Qjbim2ndetigaO5B3EyVO0S1Mo1djD37wMj8+2gff8T63fgKOjdgxtugF/+Erp0gaOPhmOPtWbixEYCimrdy2axIKOPRoOTQC0ohOMpdmB3zrWMsrWr+bFYbTCprLKAUFllmc7O4HeYnvi0gZ3c2ZkWZMKaTGamjRON1tbwqqO166dxTbg9MiOWufXp0fKSmqoFhsINltkdOKruPEvLYNlqy9C6d4FhgyzTrxNsg4JHt64NZzytobraMuV1RZbG0UMteMbv44qdFuw2bApKvFjBoUdXa3p2a/y4ULXMuWgrFG2x/RxeoiqvtHkNG2gZbVPH1sYtsORTK8CM28f2ezIqd8J7H9txfPD+De/j8Nwr3GAZcGbECgKD+lnaNm+HzdusMBaL2Xr06BoUqIKmc64dl9VRu1xWuMEy9vz+MGSgzVPVAs/aIqt9qVrtKpIRFFZ27lqwCq8ehE0y6x6N1l4lKd4BJaVwwCg7LlPgAYQWBJD2Fo1atb5wgx34kYgdtGPHQI+uPPMMTJ5szZAh8PrrsDh4m1iXLnDUUXDppfCVr6Re43ctsHGL1UYyIxZEOufa5ZO1G+3kH5lvhYOOcN29uNQeyNhRbpnTyHwLdJ9vstI5WEbZv2/Lgqyqza9oq13qGZiXXOCIt3kbfLjCagnj9rHg1ZhoFBYutZrjwftTVNaJ++6D00+HceMaSWdxqZ17m7bV1uLAAl+fnlbg6NWt6UukFZUWpDdusf0+sK/VJErL7dgY0NeCVKfcutNVVdfWFLOzrLDRGseKasrz8QDCbhRAQmUVsGKNndxjR0PXzixZAocdBvvsA2+8AZ062ahFRTBnjgWTF16AlSth9Gj4yU/goovsKoNrmiq88go89xyMHw/HHAOjRjV+3hUVWQAfNw769Al6lpbBh8utRpUZsUxhUJ5dLkq29BzYtg0eeAAeeQQ6d7b01G9ELB1FRbBxY207O9vWY/x46NWrkZUu3GBBLrz0mpttQa5/X8uw25AqzJwJf/oT9O0LY8fCgQdae+TIeoWgrcV2HzA7yy5HNfSkoSp8tMKCwNjRVPfoyUkn2fkBVlP/xjfgggsa2S7lFXZjP5JhgSPVm+3FO+yqwvZSm8egftC/d8qlO1WorITc3KbHbS0eQGidABKLQWEhLFsGn3wCa9faSZqba5l5p0613VlZ1mRm1rYzMy1D+Pxza9avr22PHQs33wzdu9dbaFByKC6GL3wBNm+GBQus9pFINApPPQW/+Y2NN2gQ/OhH8O1vQ9fUarDEYrBoEcyebc38+TavvDw76fPyapuuXW0bhE24TfLyYMSI1NPQllThpZfgV7+Ct9+2/RTexx00yALJMcfY9l+71rbre+9ZsyZ4qU7//vDww3YpEbCgsXSVtUcPadZNVVVLx733wqOPQnm5BYGsLFixArZubXoe9Q0ZAhMm2HyOPhpOPrleflhRaaXl7sElqiQyy5ISO34rK+12RdhUVkLv3nDwwY0X1N980wo5c+dasFCFTz+tHZ6bC/vvD1On2vErgtUQPlhmGfu+IyzYZWVahhymeWWh3bscNQTy+3PNNfDb38Jdd9mxfN99djzn5MCXv2zB5PjjW/6A2mefwfbtcNBB9Qa0wiPEsRg88QT84hewZImdd0OGwNChte3Ro+HEE6Fbt6bn1xweQEg9gDz4oJWQPvkEli+HioraYfE13FR07w4DBljmOneuHQQzZsAXv1h3vFgMpkyB55+HWbPiMqlGqNq4v/kNvPaalbSOPbY2049vunQJHuyJ1rajUQtss2fb9JuDv53stx8ceaRlFGGpd9Mma5eXN5okwJY3fLgFkxEjrHvYMFv3YcOaf/CrWml71SrLQ3r1ssyrR4+mMwRVePFFCxzvvGNpuPZauOQSy6j//e/a5vPPa6cTgX33hUMOsWbkSPjf/7WCxa9/DT/9aePL/vRTqzGqxj2EFbQ3bIC//Q0++MCC7YUXWgZ6yCG102/darXMFSusEbH92q9f3WBeXm4Z5cKFte2lS23fXnyxlfo7N/O+6mefwTPPWPP663arqiEDBsCXvgRnnmkZW5cghi5ZYtvrqacsQN9wg6UnMxNKS+Hjj61W9+GHVtN+912bz333WaCmtMzuC8Y/iCASPOWXabX2gX1hzDCeelqYMgUuvxzuuad29P/+F6ZPh4cesu05bpxlzlOmJB9IduywY+Oll6xZutT6X3op3HabHYMtpWrn/c9/bvvvgAPs8vTnn9u+WLPGmu3bbfycHCscfPnLtt1rasUt4AGE1APIz34Gjz9ul43GjKnbHjTIMveKCmvKy62pqLATq7q6bruqCnr2tBNrwIC6J+/cufC1r1lGeM01dpM8O7jM+6tfwfXXw+23w/e/3/x1f+cd+MMf7ITctMmahh6Cqi8/H044wZrjj4fBgxset6zMTqpwW8Rvl88/t4xz1Sprf/oprF5tgSher14WSPLzLZh06WIZadjOzrZaYJiBrlxpy61PxLZ1GEzqz6dLF5g3zzKnYcPguussE8tOcGld1QoP8+ZZkBk/ftdAV1JiGf3DD9t19hkzdj15586F3//eCiSJnrANTZxo87rggtYvTZaXW2n8hhuspPzEE1Zybcz778OTT8LTT1smBhZAJ0+2eeTkWJOdXdtetQqefdYC9PbtVps4/ngLbA8+aMf+NdfAVVc1HsRiMas5/OQnVuCaPh3OOAMr0ZfsqPtkX9jkZsPIfJavzGDiRDtX33wz8aXcigqr5d10kxUSx461QHLOObsGkspKq33PmWOFszfftOM3N9dqqKecYoWZW26xvOG++ywzT6S01Nblb3+z4/GAA+zSXdj07w+vvmr5z9tv26XK66+3YyLR1a/iYts3M2favvrsMxvvuOMsmJx7rm37VHgAYfe4B1JSAj/8oR14hxxipaNPPrET9aKL4O9/b537abGYndRhMCkrq73EFonUtnv2tBpCW93vjcUssKxevWuzbp2dZDt21LbDTLdzZyv1xzcjRlhGv2WLNVu3WnvzZtuu9ee1Y4fVhq6+2rZtosDRXKpWyv3hD62A8NhjFgyefhpuvdUCSM+eVhq+6CK7vBc+CR0+IJeTY9u8rb34otVuqqvh/vvh7LPrDq+qsozojjvgrbfsGDjySDsWzzrLAkgyqqqsFvHss9asXg3f/a5ljM3J0D78EP7f/7NgdvnlFogbCzxlZXDEEVbYeO89KyQ0Jhq1+0w33mg1pAMPtDT27WsBY84cK4iFVyDGjrWAccopdsUg/p7Eu+9aYWTJErv09rvf1RYECgvhzjvt8uT27XZPMzvb1i/+0mS3bnbc5udbQLvkkiYe2Y+japdZn3jCmmXL7N7oaaclN319DQUQezPlXtJMnDhRdxdPPqnap49qp06qXbuqTpyoWlaW7lSlVyxm22DLFuvuyObNUx0+XDUry9qgOmKE6h13qJaUpDt1tVatUi0osPRdfbVqVZXqxo2qv/616qBB1n/kSNU//MH6t1QsprpzZ+rTV1So/vjHqiKq++6r+vLLiecXi6ledJGN969/NW8Z1dWq//yn6gEH1D73nZFh2+lHP1KdOVO1qKjp+ZSVqf7P/1gahg9XffBB1a99TTUz0+b3la+ozp1bN83r16vOmqV6++2ql1+ueuedquXlzUt/fbGY6uLFqpWVqc8DmK8J8tS0Z+rt2exOAURVdd061dNPVx08WHX16nSnxjXXli2qF16oetxxqo8/bhlTR1RRofqd71husN9+qjk51n3SSarPPtsx0z17tmp+vqWzZ0/V889Xfegh2+aqqvfea8N++cvUlxGNqj7/vOqLL6oWF6c+nzfeUB01ytLTtavqVVeprlyZ+vzSoaEA4pewdgPh/5aca0sPPmgPXBx7LFx5pT391JHt2AEvv2yXxZ5/3u49RCL2P6i337Zr/88/3zH+C7Vjhz2IcvTRdglzd+P3QNh9A4hzrnGxmN13CO+zVFfbPYu+SbyWzDXNAwgeQJxzLhUNBRC/MOKccy4lHkCcc86lJK0BREROFZGlIrJcRK5JMPxqEVkYNItFJCoivYNhq0Tkg2CYX5dyzrl2lrYPSolIBLgbOAkoBOaJyDOq+lE4jqr+DvhdMP6ZwA9VdUvcbI5T1U3tmGznnHOBdNZADgOWq+pKVd0JPAxMbmT8C4B/tkvKnHPONSmdAWQwsCbud2HQbxci0hk4FXgirrcCL4vIAhGZ2tBCRGSqiMwXkflFRUWtkGznnHOQ3gCS6O1KDT1TfCbwn3qXr45S1UOA04ArRGRSoglVdZqqFqhqQV6qbxJzzjm3i3QGkEIg/osW+cC6BsY9n3qXr1R1XdDeCMzELok555xrJ+kMIPOAMSIyQkSysSDxTP2RRKQHcAzwdFy/LiLSLewGTgYWt0uqnXPOAWl8CktVq0XkSuAlIAJMV9UPReTyYPifg1GnAC+r6o64yfsDM8XeMZ4J/ENVX2y/1DvnnPNXmTjnnGuUv8rEOedcq/IA4pxzLiUeQJxzzqXEA4hzzrmUeABxzjmXEg8gzjnnUuIBxDnnXEo8gDjnnEuJBxDnnHMp8QDinHMuJR5AnHPOpcQDiHPOuZR4AHHOOZcSDyDOOedS4gHEOedcSjyAOOecS0laA4iInCoiS0VkuYhck2D4sSKyXUQWBs0vkp3WOedc20rbJ21FJALcDZwEFALzROQZVf2o3qhvqOoZKU7rnHOujaSzBnIYsFxVV6rqTuBhYHI7TOucc64VpDOADAbWxP0uDPrVd4SILBKRf4nIgc2cFhGZKiLzRWR+UVFRa6TbOecc6Q0gkqCf1vv9HjBMVccDdwJPNWNa66k6TVULVLUgLy8v1bQ655yrJ50BpBAYEvc7H1gXP4KqFqtqadD9ApAlIn2TmdY551zbSmcAmQeMEZERIpINnA88Ez+CiAwQEQm6D8PSuzmZaZ1zzrWttD2FparVInIl8BIQAaar6ocicnkw/M/AucB3RKQaKAfOV1UFEk6blhVxzrm9lFh+vHcoKCjQ+fPnpzsZzjm3WxGRBapaUL+//xPdOedcSjyAOOecS4kHEOeccynxAOKccy4lHkCcc86lxAOIc865lDQZQETkKyLSLej+mYg8KSKHtH3SnHPOdWTJ1EB+rqolInI0cApwP3BP2ybLOedcR5dMAIkG7S8B96jq00B22yXJOefc7iCZALJWRO4Fvgq8ICI5SU7nnHNuD5ZMIPgq9s6pU1V1G9AbuLotE+Wcc67jS+ZligOB51W1UkSOBcYBM9oyUc451xJVVVUUFhZSUVGR7qTsVnJzc8nPzycrKyup8ZMJIE8ABSIyGrgPe236P4DTU06lc861ocLCQrp168bw4cMJvgjhmqCqbN68mcLCQkaMGJHUNMlcwoqpajXwZeCPqvpDrFbinHMdUkVFBX369PHg0QwiQp8+fZpVa0smgFSJyAXARcBzQb/k6jfOOZcmHjyar7nbLJkAcilwBHCTqn4qIiOAB1NIm3POuT1IkwFEVT8Cfgx8ICJjgUJVvbk1Fi4ip4rIUhFZLiLXJBh+oYi8HzRvicj4uGGrROQDEVkoIv6VKOeca2dN3kQPnry6H1gFCDBERC5W1TktWbCIRIC7gZOAQmCeiDwTBKzQp8AxqrpVRE4DpgFfiBt+nKpuakk6nHPOpSaZp7B+D5ysqksBRGQf4J/AxBYu+zBguaquDOb7MDAZqAkgqvpW3PhvA/ktXKZzbi9z1YtXsfDzha06zwkDJvDHU//Y6Dhnn302a9asoaKigh/84AdMnTqVF198kWuvvZZoNErfvn2ZPXs2paWlfO9732P+/PmICL/85S8555xzWjW9bSWZAJIVBg8AVf1ERFrjJvpgYE3c70Lq1i7q+ybwr7jfCrwsIgrcq6rTWiFNzjnXKqZPn07v3r0pLy/n0EMPZfLkyVx22WXMmTOHESNGsGXLFgBuvPFGevTowQcffADA1q1b05nsZkkmgMwXkfuAB4LfFwILWmHZiW73a8IRRY7DAsjRcb2PUtV1ItIPeEVEliS6rCYiU4GpAEOHDm15qp1zu5Wmagpt5Y477mDmzJkArFmzhmnTpjFp0qSa/1j07t0bgFmzZvHwww/XTNerV6/2T2yKknkK6zvAh8D3gR9gl5gub4VlFwJD4n7nA+vqjyQi44C/ApNVdXPYX1XXBe2NwEzsktguVHWaqhaoakFeXl4rJNs55xr3+uuvM2vWLObOncuiRYs4+OCDGT9+fMLHZFV1t33kOJmnsCpV9Q+q+mVVnaKqt6lqZSssex4wRkRGiEg2cD72L/caIjIUeBL4uqp+Ete/S9w3SroAJwOLWyFNzjnXYtu3b6dXr1507tyZJUuW8Pbbb1NZWcm///1vPv30U4CaS1gnn3wyd911V820u9MlrAYDSPCI7PsNNS1dcPDv9iuxFzV+DDyqqh+KyOUiEtZwfgH0Af5U73Hd/sCbIrIIeBd7V9eLLU2Tc861hlNPPZXq6mrGjRvHz3/+cw4//HDy8vKYNm0aX/7ylxk/fjznnXceAD/72c/YunUrY8eOZfz48bz22mtpTn3yRDXhbQdEZFhjE6rq6jZJURsqKCjQ+fP9LyPO7ek+/vhj9t9//3QnY7eUaNuJyAJVLag/boM30XfHAOGcc679+IehnHPOpcQDiHPOuZSkFEBEpE9rJ8Q559zuJekAIiIrROQOETkMeKMN0+Scc243kHQAUdVR2MsN5wKt8jZe55xzu6/G/gfycvyjvCJyOPYP9G8DZ7RD2pxzbrd15JFHpjsJba6xGki/8FFeEfkSMB04U1X/CiT3wVznnNtLvfXWW02PtJtr7GWKlSJyMfa+qu8DB6vqWhHpDnRpl9Q551wLXXUVLFzYuvOcMAH++MfGx+natSulpaW8/vrr3HrrrTz3nH0R/Morr6SgoIBLLrkk4XQ33HADzz77LOXl5Rx55JHce++9iAjLly/n8ssvp6ioiEgkwmOPPcaoUaO45ZZbeOCBB8jIyOC0007j5pvb7w5DYzWQC4EvAoOA3wL3i8gvgNeAv7RD2pxzbq9z5ZVXMm/ePBYvXkx5eXlN4Lnwwgu54oorWLRoEW+99RYDBw7kX//6F0899RTvvPMOixYt4ic/+Um7prWxf6IvB74V/haRV4ETgZ+q6qx2SJtzzrVYUzWFjua1117jlltuoaysjC1btnDggQdy7LHHsnbtWqZMmQJAbm4uYK+Cv/TSS+ncuTNQ+4r49pLM90AAUNX/Av9tw7Q459weJzMzk1gsVvO7oqKiwXErKir47ne/y/z58xkyZAjXX389FRUVNPTOwnS/Ct7/ie6cc21o2LBhfPTRR1RWVrJ9+3Zmz57d4LhhcOnbty+lpaU8/vjjAHTv3p38/HyeeuopACorKykrK+Pkk09m+vTplJWVAbWviG8vSddAnHPONd+QIUP46le/yrhx4xgzZgwHH3xwg+P27NmTyy67jIMOOojhw4dz6KGH1gx74IEH+Pa3v80vfvELsrKyeOyxxzj11FNZuHAhBQUFZGdnc/rpp/N///d/7bFaQCOvc68ZQeQM4AVVjTU64m7AX+fu3N7BX+eeuua8zj2ZS1jnA8tE5BYR8T3inHMOSOISlqp+LfjvxwXA30REgb8B/1TVkrZOoHPO7YmmTJlS83nb0G9/+1tOOeWUNKWo+ZK6B6KqxSLyBNAJuAqYAlwtIneo6p2pLlxETgVuByLAX1X15nrDJRh+OlAGXKKq7yUzrXPOdWQzZ85MdxJarMlLWCJypojMBF4FsoDDVPU0YDzw41QXLCIR4G7gNOAA4AIROaDeaKcBY4JmKnBPM6Z1zjnXhpKpgXwFuE1V58T3VNUyEflGC5Z9GLBcVVcCiMjDwGTgo7hxJgMz1O70vy0iPUVkIDA8iWmdc861oWRuov8SeDf8ISKdRGQ4gKo2/EBz0wYDa+J+Fwb9khknmWnD9E4VkfkiMr+oqKgFyXXOORcvmQDyGBD/CG806NdSif4+Wf+Z4obGSWZa66k6TVULVLUgLy+vmUl0zjnXkGQuYWWq6s7wh6ruFJHsVlh2Ifam31A+sC7JcbKTmNY55zqE66+/nq5du1JcXMykSZM48cQT052kVpFMDaRIRM4Kf4jIZGBTKyx7HjBGREYEAel84Jl64zwDXCTmcGC7qq5PclrnnOtQbrjhhj0meEByNZDLgYdE5C7s0tEa4KKWLlhVq0XkSuAl7FHc6ar6oYhcHgz/M/AC9gjvcuwx3ksbm7alaXLO7YGWfwalZa07z66dYfTQRke56aabmDFjBkOGDCEvL4+JEydyySWXcMYZZ3Duuecyb948fvCDH7Bjxw5ycnKYPXs2nTt35pprruH111+nsrKSK664gm9/+9sJ519aWsrkyZPZunUrVVVV/PrXv2by5MkAzJgxg1tvvRURYdy4cTzwwANs2LCByy+/nJUrVwJwzz33tPiricn8kXAFcLiIdMVefdJqfx5U1RewIBHf789x3Qpckey0zjnXESxYsICHH36Y//73v1RXV3PIIYcwceLEmuE7d+7kvPPO45FHHuHQQw+luLiYTp06cd9999GjRw/mzZtHZWUlRx11FCeffDIjRuz6Edjc3FxmzpxJ9+7d2bRpE4cffjhnnXUWH330ETfddBP/+c9/6Nu3b80LFr///e9zzDHHMHPmTKLRKKWlpS1ez6T+SBh80vZAIDd8dbCq3tDipTvnXFtroqbQFt544w2mTJlS852Os846q87wpUuXMnDgwJqXJXbv3h2Al19+mffff7/mLbzbt29n2bJlCQOIqnLttdcyZ84cMjIyWLt2LRs2bODVV1/l3HPPpW/fvkDtN0JeffVVZsyYAUAkEqFHjx4tXs8mA4iI/BnoDBwH/BU4l7jHep1zzu2qse90NPQdD1XlzjvvTOp1Jg899BBFRUUsWLCArKwshg8fXvPtkPb6RkgyN9GPVNWLgK2q+ivgCOo+AeWccy7OpEmTmDlzJuXl5ZSUlPDss8/WGb7ffvuxbt065s2bB0BJSQnV1dWccsop3HPPPVRVVQHwySefsGPHjoTL2L59O/369SMrK4vXXnuN1atXA3DCCSfw6KOPsnnzZqD2GyEnnHAC99xzDwDRaJTi4uIWr2cyl7DCz2eVicggYDOwa33KOeccAIcccgjnnXceEyZMYNiwYXzxi1+sMzw7O5tHHnmE733ve5SXl9OpUydmzZrFt771LVatWsUhhxyCqpKXl1fzEan6LrzwQs4880wKCgqYMGEC++23HwAHHngg1113HccccwyRSISDDz6Yv//979x+++1MnTqV++67j0gkwj333MMRRxzRovVM5nsgPwfuBE7A3j+lwF9U9RctWnIa+PdAnNs7+PdAUtec74E0WgMRkQxgtqpuA54QkeeAXFXd3orpdc45txtqNICoakxEfo/d90BVK4HK9kiYc845+OCDD/j6179ep19OTg7vvPNOmlJUK5l7IC+LyDnAk9rU9S7nnHOt6qCDDmLhwoXpTkZCyQSQHwFdgGoRqcD+ja6q2r1NU+acc65DS+af6N3aIyHOOed2L8n8kXBSov71PzDlnHNu75LMJayr47pzsS8JLgCOb5MUOefcHqBr166t8r6pjiyZS1hnxv8WkSHALW2WIuecc7uFZF5lUl8hMLa1E+Kcc3siVeXqq69m7NixHHTQQTzyyCMArF+/nkmTJjFhwgTGjh3LG2+8QTQa5ZJLLqkZ97bbbktz6huXzD2QO6n9XGwGMAFY1IZpcs651nPVVdDaj8FOmAB//GNSoz755JMsXLiQRYsWsWnTJg499FAmTZrEP/7xD0455RSuu+46otEoZWVlLFy4kLVr17J48WIAtm3b1rrpbmXJ3AOJf/dHNfBPVf1PG6XHOef2KG+++SYXXHABkUiE/v37c8wxxzBv3jwOPfRQvvGNb1BVVcXZZ5/NhAkTGDlyJCtXruR73/seX/rSlzj55JPTnfxGJRNAHgcqVDUKICIREemsqil/4ktEegOPAMOBVcBXVXVrvXGGADOAAUAMmKaqtwfDrgcuA4qC0a8NPjDlnHN1JVlTaCsN/f960qRJzJkzh+eff56vf/3rXH311Vx00UUsWrSIl156ibvvvptHH32U6dOnt3OKk5fMPZDZQKe4352AWS1c7jXYO7bGBPO/JsE41cD/qOr+wOHAFSJyQNzw21R1QtB48HDOdUiTJk3ikUceIRqNUlRUxJw5czjssMNYvXo1/fr147LLLuOb3/wm7733Hps2bSIWi3HOOedw44038t5776U7+Y1KpgaSq6o1z6KpaqmIdG7hcicDxwbd9wOvAz+NH0FV1wPrg+4SEfkYGAx81MJlO+dcu5kyZQpz585l/PjxiAi33HILAwYM4P777+d3v/sdWVlZdO3alRkzZrB27VouvfRSYrEYAL/5zW/SnPrGJfM69/8A31PV94LfE4G7VDXlF8mLyDZV7Rn3e6uq9mpk/OHAHGCsqhYHl7AuAYqxezT/U/8SWNy0U4GpAEOHDp0YfnTFObfn8te5p67VXuceuAp4TETWBb8HAuc1NZGIzMLuX9R3XRLLjJ9PV+AJ4CpVDT+hdQ9wI/Z02I3A74FvJJpeVacB08C+B9KcZTvnnGtYMn8knCci+wH7Yi9SXKKqVUlMd2JDw0Rkg4gMVNX1IjIQ2NjAeFlY8HhIVZ+Mm/eGuHH+AjzXVHqcc861riZvoovIFUAXVV2sqh8AXUXkuy1c7jPAxUH3xcDTCZYrwH3Ax6r6h3rDBsb9nAIsbmF6nHN7GP/6RPM1d5sl8xTWZcEXCcMFbMUeoW2Jm4GTRGQZcFLwGxEZJCLhE1VHAV8HjheRhUFzejDsFhH5QETeB44DftjC9Djn9iC5ubls3rzZg0gzqCqbN28mNzc36WmSuQeSISISfkxKRCJAdoppBEBVN2PfWK/ffx1wetD9JnbJLNH0X0/U3znnAPLz8yksLKSoqKjpkV2N3Nxc8vPzkx4/mQDyEvCoiPwZu2l9OfBiaslzzrm2l5WVxYgRI9KdjD1eMgHkp9hjsN/BagQvA39py0Q555zr+Jq8B6KqMVX9s6qeq6rnAB8Cd7Z90pxzznVkydRAEJEJwAXY/z8+BZ5sdALnnHN7vAYDiIjsA5yPBY7N2MsPRVWPa6e0Oeec68Aaq4EsAd4AzlTV5QAi4o/LOuecAxq/B3IO8Dnwmoj8RUROoIHHap1zzu19GgwgqjpTVc8D9sPelvtDoL+I3CMiHfsrJ84559pcMk9h7VDVh1T1DCAfWEji73c455zbiyTzKpMaqrpFVe9V1ePbKkHOOed2D80KIM4551zIA4hzzrmUeABxzjmXEg8gzjnnUuIBxDnnXEo8gDjnnEtJWgKIiPQWkVdEZFnQ7tXAeKuCLw8uFJH5zZ3eOedc20lXDeQaYLaqjgFm0/gfE49T1QmqWpDi9M4559pAugLIZOD+oPt+4Ox2nt4551wLpSuA9FfV9QBBu18D4ynwsogsEJGpKUyPiEwVkfkiMt+/j+ycc60nqQ9KpUJEZgEDEgy6rhmzOUpV14lIP+AVEVmiqnOakw5VnQZMAygoKNDmTOucc65hbRZAVPXEhoaJyAYRGaiq60VkILCxgXmsC9obRWQmcBgwB0hqeuecc20nXZewngEuDrovBp6uP4KIdBGRbmE3cDKwONnpnXPOta10BZCbgZNEZBlwUvAbERkkIi8E4/QH3hSRRcC7wPOq+mJj0zvnnGs/bXYJqzGquhk4IUH/dcDpQfdKYHxzpnfOOdd+/J/ozjnnUuIBxDnnXEo8gDjnnEuJBxDnnHMp8QDinHMuJR5AnHPOpcQDiHPOuZR4AHHOOZcSDyDOOedS4gHEOedcSjyAOOecS4kHEOeccynxAOKccy4lHkCcc86lxAOIc865lHgAcc45l5K0BBAR6S0ir4jIsqDdK8E4+4rIwrimWESuCoZdLyJr44ad3u4r4Zxze7l01UCuAWar6hhgdvC7DlVdqqoTVHUCMBEoA2bGjXJbOFxVX6g/vXPOubaVrgAyGbg/6L4fOLuJ8U8AVqjq6rZMlHPOueSlK4D0V9X1AEG7XxPjnw/8s16/K0XkfRGZnugSWEhEporIfBGZX1RU1LJUO+ecq9FmAUREZonI4gTN5GbOJxs4C3gsrvc9wChgArAe+H1D06vqNFUtUNWCvLy85q+Ic865hDLbasaqemJDw0Rkg4gMVNX1IjIQ2NjIrE4D3lPVDXHzrukWkb8Az7VGmp1zziUvXZewngEuDrovBp5uZNwLqHf5Kgg6oSnA4lZNnXPOuSalK4DcDJwkIsuAk4LfiMggEal5okpEOgfDn6w3/S0i8oGIvA8cB/ywfZLtnHMu1GaXsBqjqpuxJ6vq918HnB73uwzok2C8r7dpAp1zzjXJ/4nunHMuJR5AnHPOpcQDiHPOuZR4AHHOOZcSDyDOOedS4gHEOedcSjyAOOecS4kHEOeccynxAOKccy4lHkCcc86lxAOIc865lHgAcc45l5K0vExxjxaNwscfw+LF0LMnDBsGQ4ZA167pTlnDtm2Dykro1w9E2nfZVVWgCtnZyY1fUQHr19t0YNOGDUDv3pCXBxmNlI127IDly62JRuGEE6DPLu/sbHvRKEQi7b9c1zHt2AELF8KCBdYsXAhjxsB118HBB6c2z02bYN48a77xDcjPb80UewBpkVgMPvvMds6771qzYIEdCPX17g1Dh1pACdvxTV6eZd6qlpmXlEBxsbUzMmC//ZLPZOurqoING2DdOli5EpYts8xz2TJrNm2y8XJyLNjVT+eIEdbk5yfO8KqrobAQPv3Umm3bbBvEN6Wlti7btsH27bXtsjKbR9++MHhw3aZ7d1i7Flavtu28erWtR1MyM2HAABg0qLapqKhd5/Xr646fkQFHHglnnglnnAH77183kKrC1q22/MJCGz83t27TqRP07w9dujScrh074PXX4aWXrPnkE5u2a1fo1q226dXLMowjjoAvfMGOnUTKyqyw8uGHlqbwWBo0yLZBU1Rte8YfD599BllZth6dO9dtd+9uhaIePawddmdmws6ddpzt3Fnb5OTYfszKajotrWXTJpg7FzZvhqOPhlGjWl4oqqy0Y2bdOjse162zRgRGjrRljBpl5054fkSjsGIFfPCBNe+/b9s4ErF9npNTe+xEIrBkiTWxmE3fvz+MHw+zZsETT9ix+fOfw6GHNpzOkhKYP9/yo7C9apUNE7FjqpUDiGhYctsLFBQU6Pz585s/4ccfW2ng009th4TN6tV2ooBl7gcfbDv4sMNs55eU2AkZZn7x7eLiusvIzbUTtaSktnQdLzMTDjjA5jthgrX32ccy4Y0bLSOIb4cH/Lp1UFRUW0IPDR5spZuwyc2FNWvqpnH9+rrTZWVZUBk5EgYOtOErV9r41dW7pjk72zKesOnefdfMp2dPO2nCkzNsNm6s3S71g+7gwXYCgp0Y8RnE5s216x02a9daWsJ1HT26tl1ZCS+8AM8+a/sYLFh+8YuWGa1ebU1paZOHCWAn/siR1owYYe2iIgsYb75px0unTnDssVBQYIGtpKQ2wJaU2Lp/9FFtZrLPPhZMJk60eS1ebJnSihW77lewDCk/37ZV7962b+o3JSU2ffx6hdNFoxacysosfS2RkWEBLb6wNHCgrVtVlaWlqqo2+BQX1y1gbNtm/Xr3tv01erRl1mH39u3w1lu1zbJldZc/eLBt67AZNQrKy+38XbmyttDz2We1BZqw0BN2b9++63qFhbnw/Ac7P4YPtwLBkiW2nHAbjBkD++5rvysq7LirqLBm5047TiZOrG0GDbLjets2uPNOuO02K8Scdhr84heWxyxdCm+/XdssXlx7zIwYYXlRQYG1DznEzr8UicgCVS3Ypb8HkCRccQX86U/WnZdnO2f4cGtGjrSddNBBzashbNtWmzmFTUWF7eSwJBp2V1RYCWbRImvWrWt4vpGIXYoaONAOwvj2wIGW5tGjLVg1ZedOCyrhSRaecCtXWvAYNKg2kwwzzBEj7GTv0qVlJc+dOy1z69Wr/S6rFRbC889bMFmwwGox8Rnf8OG1Jbjw5A+bsjLbL+H2WbnSMqXwhD7oIDjlFGuOPtoCY2NKS60UOXdubQaxcWNtZjR2rM1z7FhrYNfjafVqO86ysqwAkplpx0dmpu3/UaPqBtShQ3fdZ9GoZYQ7dlhGHp+xh00sZtNlZ1sTdpeV1RZIwqawMHFhA2y6sJYTX8Do1s2C+fLltl0TFbDy8qwWGTa9e8Mbb1iN77XXamuu3bpZ8IzXqZPt2549a2tb8TWvsHYc1mYHD7b5x2JWOFmxom5TXGyFvXHjbB8dcIAtoyWKiy0PuvVWKyR17Vob/Hv2tJpqWGMtKLA0t6IOFUBE5CvA9cD+wGGqmjBXF5FTgduBCPBXVQ2/XNgbeAQYDqwCvqqqW5tabsoBZOVKyySGDWv8EkV7KSqyQLJihWWw/fpZybdfP/vd2PV/136qqiwD7dzZgndLqFqA6tOn6eDTkUWjsGWLBbKsrNrgFokkV1CIRi0IhfewOnWygNHYpSpVK62//rqV0sOCT9ik495fqkpLYdo0W/fDDoPDD7caahuf8x0tgOwPxIB7gR8nCiAiEgE+wT5pWwjMAy5Q1Y9E5BZgi6reLCLXAL1U9adNLTflAOKcc3uxhgJIWoqqqvqxqi5tYrTDgOWqulJVdwIPA5ODYZOB+4Pu+4Gz2yShzjnnGtSRr3UMBtbE/S4M+gH0V9X1AEG7X0MzEZGpIjJfROYXFRW1WWKdc25v02aP8YrILGBAgkHXqerTycwiQb9mX29T1WnANLBLWM2d3jnnXGJtFkBU9cQWzqIQGBL3Ox8IHz/aICIDVXW9iAwENrZwWc4555qpI1/CmgeMEZERIpINnA88Ewx7Brg46L4YSKZG45xzrhWlJYCIyBQRKQSOAJ4XkZeC/oNE5AUAVa0GrgReAj4GHlXVD4NZ3AycJCLLsKe0bm7vdXDOub2d/5HQOedcozrUY7zOOed2f3tVDUREioDVTYzWF9jUDsnpaHy99y6+3nuflqz7MFXNq99zrwogyRCR+Ymqans6X++9i6/33qct1t0vYTnnnEuJBxDnnHMp8QCyq2npTkCa+HrvXXy99z6tvu5+D8Q551xKvAbinHMuJR5AnHPOpcQDSEBEThWRpSKyPPhI1R5LRKaLyEYRWRzXr7eIvCIiy4J2r3SmsS2IyBAReU1EPhaRD0XkB0H/PXrdRSRXRN4VkUXBev8q6L9HrzfYh+lE5L8i8lzwe49fZwARWSUiH4jIQhGZH/Rr9XX3AELN1w/vBk4DDgAuEJED0puqNvV34NR6/a4BZqvqGGB28HtPUw38j6ruDxwOXBHs5z193SuB41V1PDABOFVEDmfPX2+AH2Dv0gvtDescOk5VJ8T996PV190DiGns64d7HFWdA2yp13uP/8qjqq5X1feC7hIsYxnMHr7uakqDn1lBo+zh6y0i+cCXgL/G9d6j17kJrb7uHkBMY18/3Fsk/ZXHPYGIDAcOBt5hL1j34FLOQuzbOa+o6t6w3n8EfgLE4vrt6escUuBlEVkgIlODfq2+7m32QandTKt8/dDtHkSkK/AEcJWqFosk2v17FlWNAhNEpCcwU0TGpjlJbUpEzgA2quoCETk2zclJh6NUdZ2I9ANeEZElbbEQr4GYxr5+uLfYEHzdkT35K48ikoUFj4dU9cmg916x7gCqug14HbsHtiev91HAWSKyCrskfbyIPMievc41VHVd0N4IzMQu07f6unsAMY19/XBvscd/5VGsqnEf8LGq/iFu0B697iKSF9Q8EJFOwInAEvbg9VbV/1XVfFUdjp3Pr6rq19iD1zkkIl1EpFvYDZwMLKYN1t3/iR4QkdOxa6YRYLqq3pTeFLUdEfkncCz2eucNwC+Bp4BHgaHAZ8BXVLX+jfbdmogcDbwBfEDtdfFrsfsge+y6i8g47KZpBCs0PqqqN4hIH/bg9Q4Fl7B+rKpn7A3rLCIjsVoH2G2Kf6jqTW2x7h5AnHPOpcQvYTnnnEuJBxDnnHMp8QDinHMuJR5AnHPOpcQDiHPOuZR4AHGuFYlINHgDati02sv6RGR4/BuUnUs3f5WJc62rXFUnpDsRzrUHr4E41w6C7zP8Nvgux7siMjroP0xEZovI+0F7aNC/v4jMDL7hsUhEjgxmFRGRvwTf9Xg5+Ge5c2nhAcS51tWp3iWs8+KGFavqYcBd2FsPCLpnqOo44CHgjqD/HcC/g294HAJ8GPQfA9ytqgcC24Bz2nRtnGuE/xPduVYkIqWq2jVB/1XYR51WBi90/FxV+4jIJmCgqlYF/deral8RKQLyVbUybh7DsVexjwl+/xTIUtVft8OqObcLr4E41360ge6GxkmkMq47it/HdGnkAcS59nNeXHtu0P0W9rZYgAuBN4Pu2cB3oOZjUN3bK5HOJctLL861rk7Bl/9CL6pq+Chvjoi8gxXcLgj6fR+YLiJXA0XApUH/HwDTROSbWE3jO8D6tk68c83h90CcawfBPZACVd2U7rQ411r8EpZzzrmUeA3EOedcSrwG4pxzLiUeQJxzzqXEA4hzzrmUeABxzjmXEg8gzjnnUvL/AcV4rVDaOc+lAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training accuracy and loss plot\n",
    "plt.plot(epochs, val_acc, color='green', label='Testing accuracy')\n",
    "plt.plot(epochs, val_iu_acc, color='blue', label='Testing iu_accuracy')\n",
    "plt.plot(epochs, val_dice_acc, color='pink', label='Testing dice_accuracy')\n",
    "plt.plot(epochs, val_loss, color='red', label='Testing loss')\n",
    "plt.title('Testing acc and loss')\n",
    "plt.ylabel('Accuracy & loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['acc', 'iu_acc', 'dice_acc','loss'], loc='best')\n",
    "\n",
    "plt.savefig(\"D:/Anil/saved_model/UNet/Testing_acc_loss_pretrained_UNet_50epochs_10000_it.png\", bbox_inches=\"tight\", pad_inches=2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "model = get_unet(path_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 512, 512, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "dim = (512,512)\n",
    "# path_test = 'D:/Dataset/Gray_mold/Unet_data/Preprocessed/test/'\n",
    "testimg = np.zeros([1,512,512,3], dtype='uint8')\n",
    "# img = cv2.imread((\"D:/Anil/Dataset/gray_mold/test/img/img_110.png\"),1)\n",
    "img = cv2.imread((\"D:/Anil/Dataset/gray_mold/test/img/img_109.png\"),1)\n",
    "img = cv2.resize(img,(512,512),interpolation = cv2.INTER_AREA)\n",
    "b,g,r = cv2.split(img)\n",
    "test_img = cv2.merge([r,g,b])\n",
    "# img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "                  \n",
    "# img = cv2.imread(os.path.join(path_test, 'img/', 'img_'+np.str(50) + '.png'),1)\n",
    "# b,g,r = cv2.split(img)\n",
    "# img = cv2.merge([r,g,b])\n",
    "# cv2.imshow('original image',img)\n",
    "# cv2.imshow('blue',b)\n",
    "# cv2.imshow('green',g)\n",
    "# cv2.imshow('red',r)\n",
    "# cv2.imshow('merg image',merg_img)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "norm_img = test_img/255.0\n",
    "testimg = np.reshape(norm_img,(1,512,512,3))\n",
    "testimg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "#%% predict \n",
    "# model = get_unet(weight_path)\n",
    "# test_data = test_data()\n",
    "y_pred = model.predict(testimg, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.reshape(y_pred,(512,512,1))\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred*255\n",
    "\n",
    "if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "cv2.imshow(\"original image\",img)\n",
    "cv2.imshow('predicted image',y_pred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the model\n",
    "filepath=\"E:/Dataset/Gray_mold/Unet_data/model_Unet_10epochs.hdf5\"\n",
    "model.save(filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = \"E:/Dataset/Gray_mold/Unet_data/model_weight_Unet_10epochs.h5\"\n",
    "model.save_weights(weight_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"D:/Dataset/Gray_mold/test_sample_x.png\", y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
